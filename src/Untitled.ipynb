{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ce1c471-c980-4074-98bc-df9c7e3ce1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Technical diagnostic report saved: ./docs/TECHNICAL_DIAGNOSTIC.md\n",
      "   Issues found: 0\n",
      "   Warnings: 0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# ğŸ”§ Technical System Diagnostic Report\n",
       "\n",
       "*Generated: 2025-11-07 22:06:43*\n",
       "*Quick Mode: OFF*\n",
       "\n",
       "---\n",
       "\n",
       "## 1. ğŸ¥ System Health Check\n",
       "\n",
       "**Overall Status**: âœ… HEALTHY\n",
       "\n",
       "### Component Status\n",
       "| Component | Status | Details |\n",
       "|-----------|--------|---------|\n",
       "| data | âœ… | 3769 rows |\n",
       "| model | âœ… | Trained |\n",
       "| detector_coverage | âœ… | 0 detectors with <70% coverage |\n",
       "| data_freshness | âœ… | 3 days old |\n",
       "| data_completeness | âœ… | 79.1% complete |\n",
       "\n",
       "## 2. ğŸ›ï¸ Model Configuration Deep Dive\n",
       "\n",
       "### Anomaly Detector Configuration\n",
       "```python\n",
       "contamination: 0.050\n",
       "n_estimators: 100\n",
       "max_samples: auto\n",
       "random_state: 42\n",
       "```\n",
       "\n",
       "### Individual Detector Parameters\n",
       "| Detector | Features Used | Coverage | Active |\n",
       "|----------|--------------|----------|--------|\n",
       "| vix_mean_reversion | 18 | 100.0% | âœ… |\n",
       "| vix_momentum | 18 | 100.0% | âœ… |\n",
       "| vix_regime_structure | 18 | 100.0% | âœ… |\n",
       "| cboe_options_flow | 39 | 100.0% | âœ… |\n",
       "| cboe_cross_dynamics | 17 | 100.0% | âœ… |\n",
       "| vix_spx_relationship | 17 | 100.0% | âœ… |\n",
       "| spx_price_action | 15 | 75.0% | âœ… |\n",
       "| spx_volatility_regime | 20 | 90.9% | âœ… |\n",
       "| cross_asset_divergence | 23 | 88.5% | âœ… |\n",
       "| tail_risk_complex | 15 | 83.3% | âœ… |\n",
       "| futures_term_structure | 27 | 100.0% | âœ… |\n",
       "| macro_regime_shifts | 19 | 100.0% | âœ… |\n",
       "| momentum_acceleration | 20 | 100.0% | âœ… |\n",
       "| percentile_extremes | 19 | 100.0% | âœ… |\n",
       "| random_4 | 0 | 0.0% | âœ… |\n",
       "\n",
       "## 3. ğŸ”„ Data Pipeline Flow Trace\n",
       "\n",
       "### Data Sources â†’ Features â†’ Models\n",
       "```\n",
       "Data Fetching...........................       âœ… OK\n",
       "  â†³ VIX: 3769 observations\n",
       "  â†³ SPX: 3769 observations\n",
       "Feature Engineering.....................       âœ… OK\n",
       "  â†³ Generated 696 features\n",
       "  â†³ Time period: 3769 days\n",
       "Model Training..........................       âœ… OK\n",
       "  â†³ 15/15 detectors trained\n",
       "  â†³ Ensemble scores computed: 3769\n",
       "```\n",
       "\n",
       "### Feature Generation Summary\n",
       "- **Raw Market Data Points**: 7538\n",
       "- **Engineered Features**: 696\n",
       "- **Final Feature Set**: 696\n",
       "- **Data Reduction Ratio**: 0.1x\n",
       "\n",
       "## 4. ğŸ“… Data Freshness & Staleness\n",
       "\n",
       "### Last Update Times\n",
       "| Data Source | Last Update | Age (days) | Status |\n",
       "|-------------|-------------|------------|--------|\n",
       "| Main Features | 2025-11-04 | 3.9 | âŒ |\n",
       "\n",
       "### âš ï¸ Stale Features (>5% missing in recent data)\n",
       "- **SKEW**: 100.0% missing\n",
       "- **SKEW_change_21d**: 100.0% missing\n",
       "- **SKEW_zscore_63d**: 100.0% missing\n",
       "- **PCCI**: 100.0% missing\n",
       "- **PCCI_change_21d**: 100.0% missing\n",
       "- **PCCI_zscore_63d**: 100.0% missing\n",
       "- **PCCE**: 100.0% missing\n",
       "- **PCCE_change_21d**: 100.0% missing\n",
       "- **PCCE_zscore_63d**: 100.0% missing\n",
       "- **PCC**: 100.0% missing\n",
       "\n",
       "## 5. ğŸ¯ Current Anomaly Detection Breakdown\n",
       "\n",
       "### Ensemble Score: 38.1%\n",
       "\n",
       "### Detector Contributions\n",
       "| Detector | Score | Weight | Weighted Score | Agreement |\n",
       "|----------|-------|--------|----------------|-----------|\n",
       "| spx_price_action | 81.1% | 1.00 | 81.1% | ğŸ”´ |\n",
       "| tail_risk_complex | 79.9% | 1.00 | 79.9% | ğŸ”´ |\n",
       "| spx_volatility_regime | 59.1% | 1.00 | 59.1% | ğŸ”´ |\n",
       "| vix_momentum | 55.8% | 1.00 | 55.8% | ğŸŸ¢ |\n",
       "| vix_regime_structure | 52.0% | 1.00 | 52.0% | ğŸŸ¢ |\n",
       "| percentile_extremes | 43.4% | 1.00 | 43.4% | ğŸŸ¢ |\n",
       "| cross_asset_divergence | 38.4% | 1.00 | 38.4% | ğŸŸ¢ |\n",
       "| vix_mean_reversion | 37.9% | 1.00 | 37.9% | ğŸŸ¢ |\n",
       "| vix_spx_relationship | 31.3% | 1.00 | 31.3% | ğŸŸ¢ |\n",
       "| macro_regime_shifts | 13.4% | 1.00 | 13.4% | ğŸ”´ |\n",
       "| momentum_acceleration | 8.2% | 1.00 | 8.2% | ğŸ”´ |\n",
       "| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | ğŸ”´ |\n",
       "| futures_term_structure | 5.4% | 1.00 | 5.4% | ğŸ”´ |\n",
       "| cboe_options_flow | 1.5% | 1.00 | 1.5% | ğŸ”´ |\n",
       "\n",
       "### Top Features Driving Current Anomaly\n",
       "| Feature | Importance | Current Value | Z-Score |\n",
       "|---------|-----------|---------------|---------|\n",
       "| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\n",
       "| spx_lag1 | 0.088 | 6851.97 | 2.70 |\n",
       "| spx_ret_5d | 0.082 | -1.73 | -0.89 |\n",
       "| spx_lag5 | 0.082 | 6890.89 | 2.74 |\n",
       "| spx_ret_13d | 0.075 | 2.15 | 0.43 |\n",
       "| spx_ret_63d | 0.070 | 6.72 | 0.54 |\n",
       "| rsi_14 | 0.067 | 59.06 | 0.14 |\n",
       "| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\n",
       "| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\n",
       "| bb_width_20d | 0.058 | 5.64 | -0.13 |\n",
       "\n",
       "## 6. ğŸ”— Feature Correlation & Redundancy Analysis\n",
       "\n",
       "### High Correlation Pairs (>95%)\n",
       "| Feature 1 | Feature 2 | Correlation |\n",
       "|-----------|-----------|-------------|\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\n",
       "\n",
       "**Recommendation**: Consider removing 17552 redundant features to improve performance.\n",
       "\n",
       "## 7. âš¡ Performance Profiling\n",
       "\n",
       "### Execution Time Breakdown\n",
       "| Operation | Time (ms) | % of Total |\n",
       "|-----------|-----------|------------|\n",
       "| batch_10_detections | 168.6 | 89.7% |\n",
       "| single_detection | 19.3 | 10.3% |\n",
       "\n",
       "## 8. ğŸ” Common Failure Modes & Solutions\n",
       "\n",
       "âœ… No common failure modes detected.\n",
       "\n",
       "## 9. ğŸ’¡ What-If Scenario Analysis\n",
       "\n",
       "### VIX Spike to 40\n",
       "**Scenario**: If VIX suddenly spikes to 40 (crisis level)\n",
       "**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\n",
       "**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\n",
       "\n",
       "### SKEW >150\n",
       "**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\n",
       "**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\n",
       "**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\n",
       "\n",
       "### All CBOE Data Missing\n",
       "**Scenario**: If CBOE features become unavailable\n",
       "**Expected Behavior**: System continues to function with reduced capability\n",
       "**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\n",
       "\n",
       "## 10. ğŸ“Š Data Quality Heatmap\n",
       "\n",
       "### Feature Quality by Category\n",
       "| Category | Total Features | Complete | Sparse | Missing | Quality Score |\n",
       "|----------|---------------|----------|--------|---------|---------------|\n",
       "| VIX | 78 | 73 | 0 | 5 | 93.6% |\n",
       "| SPX | 47 | 44 | 0 | 3 | 93.6% |\n",
       "| CBOE | 232 | 24 | 33 | 175 | 17.5% |\n",
       "| Futures | 45 | 35 | 10 | 0 | 88.9% |\n",
       "| Macro | 14 | 11 | 1 | 2 | 82.1% |\n",
       "| Meta | 280 | 84 | 122 | 74 | 51.8% |\n",
       "\n",
       "## 11. ğŸš€ System Optimization Recommendations\n",
       "\n",
       "### ğŸŸ¢ Optimization Opportunities\n",
       "- Remove 17552 highly correlated features to reduce redundancy\n",
       "- Investigate 197 stale features with high recent missing data\n",
       "- Consider adding feature selection to reduce dimensionality\n",
       "- Implement caching for expensive feature calculations\n",
       "- Add monitoring alerts for data freshness\n",
       "\n",
       "## 12. ğŸ“– Quick Reference: Troubleshooting Guide\n",
       "\n",
       "\n",
       "### Common Issues & Quick Fixes\n",
       "\n",
       "**Issue**: System says \"data too old\"\n",
       "- **Check**: `system.orchestrator.features.index[-1]`\n",
       "- **Fix**: Run `system.refresh()` or retrain with fresh data\n",
       "\n",
       "**Issue**: Ensemble score always near 0% or 100%\n",
       "- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\n",
       "- **Fix**: Retrain system to recalculate thresholds\n",
       "\n",
       "**Issue**: Many detectors show 0% coverage\n",
       "- **Check**: CBOE files in `./CBOE_Data_Archive/`\n",
       "- **Fix**: Download CBOE historical data or disable CBOE features in config\n",
       "\n",
       "**Issue**: \"Core data fetch failed\" error\n",
       "- **Check**: Internet connection, yfinance API status\n",
       "- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\n",
       "\n",
       "**Issue**: High memory usage\n",
       "- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\n",
       "- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\n",
       "\n",
       "**Issue**: Slow detection speed (>1 second)\n",
       "- **Check**: Number of features and detectors active\n",
       "- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\n",
       "\n",
       "**Issue**: NaN/Inf values in features\n",
       "- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\n",
       "- **Fix**: Review feature_engine.py for division by zero or missing data handling\n",
       "\n",
       "\n",
       "---\n",
       "*Report generated in 2.34 seconds*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'# ğŸ”§ Technical System Diagnostic Report\\n\\n*Generated: 2025-11-07 22:06:43*\\n*Quick Mode: OFF*\\n\\n---\\n\\n## 1. ğŸ¥ System Health Check\\n\\n**Overall Status**: âœ… HEALTHY\\n\\n### Component Status\\n| Component | Status | Details |\\n|-----------|--------|---------|\\n| data | âœ… | 3769 rows |\\n| model | âœ… | Trained |\\n| detector_coverage | âœ… | 0 detectors with <70% coverage |\\n| data_freshness | âœ… | 3 days old |\\n| data_completeness | âœ… | 79.1% complete |\\n\\n## 2. ğŸ›ï¸ Model Configuration Deep Dive\\n\\n### Anomaly Detector Configuration\\n```python\\ncontamination: 0.050\\nn_estimators: 100\\nmax_samples: auto\\nrandom_state: 42\\n```\\n\\n### Individual Detector Parameters\\n| Detector | Features Used | Coverage | Active |\\n|----------|--------------|----------|--------|\\n| vix_mean_reversion | 18 | 100.0% | âœ… |\\n| vix_momentum | 18 | 100.0% | âœ… |\\n| vix_regime_structure | 18 | 100.0% | âœ… |\\n| cboe_options_flow | 39 | 100.0% | âœ… |\\n| cboe_cross_dynamics | 17 | 100.0% | âœ… |\\n| vix_spx_relationship | 17 | 100.0% | âœ… |\\n| spx_price_action | 15 | 75.0% | âœ… |\\n| spx_volatility_regime | 20 | 90.9% | âœ… |\\n| cross_asset_divergence | 23 | 88.5% | âœ… |\\n| tail_risk_complex | 15 | 83.3% | âœ… |\\n| futures_term_structure | 27 | 100.0% | âœ… |\\n| macro_regime_shifts | 19 | 100.0% | âœ… |\\n| momentum_acceleration | 20 | 100.0% | âœ… |\\n| percentile_extremes | 19 | 100.0% | âœ… |\\n| random_4 | 0 | 0.0% | âœ… |\\n\\n## 3. ğŸ”„ Data Pipeline Flow Trace\\n\\n### Data Sources â†’ Features â†’ Models\\n```\\nData Fetching...........................       âœ… OK\\n  â†³ VIX: 3769 observations\\n  â†³ SPX: 3769 observations\\nFeature Engineering.....................       âœ… OK\\n  â†³ Generated 696 features\\n  â†³ Time period: 3769 days\\nModel Training..........................       âœ… OK\\n  â†³ 15/15 detectors trained\\n  â†³ Ensemble scores computed: 3769\\n```\\n\\n### Feature Generation Summary\\n- **Raw Market Data Points**: 7538\\n- **Engineered Features**: 696\\n- **Final Feature Set**: 696\\n- **Data Reduction Ratio**: 0.1x\\n\\n## 4. ğŸ“… Data Freshness & Staleness\\n\\n### Last Update Times\\n| Data Source | Last Update | Age (days) | Status |\\n|-------------|-------------|------------|--------|\\n| Main Features | 2025-11-04 | 3.9 | âŒ |\\n\\n### âš ï¸ Stale Features (>5% missing in recent data)\\n- **SKEW**: 100.0% missing\\n- **SKEW_change_21d**: 100.0% missing\\n- **SKEW_zscore_63d**: 100.0% missing\\n- **PCCI**: 100.0% missing\\n- **PCCI_change_21d**: 100.0% missing\\n- **PCCI_zscore_63d**: 100.0% missing\\n- **PCCE**: 100.0% missing\\n- **PCCE_change_21d**: 100.0% missing\\n- **PCCE_zscore_63d**: 100.0% missing\\n- **PCC**: 100.0% missing\\n\\n## 5. ğŸ¯ Current Anomaly Detection Breakdown\\n\\n### Ensemble Score: 38.1%\\n\\n### Detector Contributions\\n| Detector | Score | Weight | Weighted Score | Agreement |\\n|----------|-------|--------|----------------|-----------|\\n| spx_price_action | 81.1% | 1.00 | 81.1% | ğŸ”´ |\\n| tail_risk_complex | 79.9% | 1.00 | 79.9% | ğŸ”´ |\\n| spx_volatility_regime | 59.1% | 1.00 | 59.1% | ğŸ”´ |\\n| vix_momentum | 55.8% | 1.00 | 55.8% | ğŸŸ¢ |\\n| vix_regime_structure | 52.0% | 1.00 | 52.0% | ğŸŸ¢ |\\n| percentile_extremes | 43.4% | 1.00 | 43.4% | ğŸŸ¢ |\\n| cross_asset_divergence | 38.4% | 1.00 | 38.4% | ğŸŸ¢ |\\n| vix_mean_reversion | 37.9% | 1.00 | 37.9% | ğŸŸ¢ |\\n| vix_spx_relationship | 31.3% | 1.00 | 31.3% | ğŸŸ¢ |\\n| macro_regime_shifts | 13.4% | 1.00 | 13.4% | ğŸ”´ |\\n| momentum_acceleration | 8.2% | 1.00 | 8.2% | ğŸ”´ |\\n| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | ğŸ”´ |\\n| futures_term_structure | 5.4% | 1.00 | 5.4% | ğŸ”´ |\\n| cboe_options_flow | 1.5% | 1.00 | 1.5% | ğŸ”´ |\\n\\n### Top Features Driving Current Anomaly\\n| Feature | Importance | Current Value | Z-Score |\\n|---------|-----------|---------------|---------|\\n| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\\n| spx_lag1 | 0.088 | 6851.97 | 2.70 |\\n| spx_ret_5d | 0.082 | -1.73 | -0.89 |\\n| spx_lag5 | 0.082 | 6890.89 | 2.74 |\\n| spx_ret_13d | 0.075 | 2.15 | 0.43 |\\n| spx_ret_63d | 0.070 | 6.72 | 0.54 |\\n| rsi_14 | 0.067 | 59.06 | 0.14 |\\n| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\\n| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\\n| bb_width_20d | 0.058 | 5.64 | -0.13 |\\n\\n## 6. ğŸ”— Feature Correlation & Redundancy Analysis\\n\\n### High Correlation Pairs (>95%)\\n| Feature 1 | Feature 2 | Correlation |\\n|-----------|-----------|-------------|\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\\n\\n**Recommendation**: Consider removing 17552 redundant features to improve performance.\\n\\n## 7. âš¡ Performance Profiling\\n\\n### Execution Time Breakdown\\n| Operation | Time (ms) | % of Total |\\n|-----------|-----------|------------|\\n| batch_10_detections | 168.6 | 89.7% |\\n| single_detection | 19.3 | 10.3% |\\n\\n## 8. ğŸ” Common Failure Modes & Solutions\\n\\nâœ… No common failure modes detected.\\n\\n## 9. ğŸ’¡ What-If Scenario Analysis\\n\\n### VIX Spike to 40\\n**Scenario**: If VIX suddenly spikes to 40 (crisis level)\\n**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\\n**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\\n\\n### SKEW >150\\n**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\\n**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\\n**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\\n\\n### All CBOE Data Missing\\n**Scenario**: If CBOE features become unavailable\\n**Expected Behavior**: System continues to function with reduced capability\\n**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\\n\\n## 10. ğŸ“Š Data Quality Heatmap\\n\\n### Feature Quality by Category\\n| Category | Total Features | Complete | Sparse | Missing | Quality Score |\\n|----------|---------------|----------|--------|---------|---------------|\\n| VIX | 78 | 73 | 0 | 5 | 93.6% |\\n| SPX | 47 | 44 | 0 | 3 | 93.6% |\\n| CBOE | 232 | 24 | 33 | 175 | 17.5% |\\n| Futures | 45 | 35 | 10 | 0 | 88.9% |\\n| Macro | 14 | 11 | 1 | 2 | 82.1% |\\n| Meta | 280 | 84 | 122 | 74 | 51.8% |\\n\\n## 11. ğŸš€ System Optimization Recommendations\\n\\n### ğŸŸ¢ Optimization Opportunities\\n- Remove 17552 highly correlated features to reduce redundancy\\n- Investigate 197 stale features with high recent missing data\\n- Consider adding feature selection to reduce dimensionality\\n- Implement caching for expensive feature calculations\\n- Add monitoring alerts for data freshness\\n\\n## 12. ğŸ“– Quick Reference: Troubleshooting Guide\\n\\n\\n### Common Issues & Quick Fixes\\n\\n**Issue**: System says \"data too old\"\\n- **Check**: `system.orchestrator.features.index[-1]`\\n- **Fix**: Run `system.refresh()` or retrain with fresh data\\n\\n**Issue**: Ensemble score always near 0% or 100%\\n- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\\n- **Fix**: Retrain system to recalculate thresholds\\n\\n**Issue**: Many detectors show 0% coverage\\n- **Check**: CBOE files in `./CBOE_Data_Archive/`\\n- **Fix**: Download CBOE historical data or disable CBOE features in config\\n\\n**Issue**: \"Core data fetch failed\" error\\n- **Check**: Internet connection, yfinance API status\\n- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\\n\\n**Issue**: High memory usage\\n- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\\n- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\\n\\n**Issue**: Slow detection speed (>1 second)\\n- **Check**: Number of features and detectors active\\n- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\\n\\n**Issue**: NaN/Inf values in features\\n- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\\n- **Fix**: Review feature_engine.py for division by zero or missing data handling\\n\\n\\n---\\n*Report generated in 2.34 seconds*'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enhanced_technical_introspector import TechnicalIntrospector\n",
    "\n",
    "introspector = TechnicalIntrospector(system)\n",
    "introspector.generate_report(quick_mode=False)\n",
    "\n",
    "# # Or specific diagnostics:\n",
    "# introspector.diagnose_current_state()\n",
    "# introspector.profile_performance()\n",
    "# introspector.check_data_freshness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52eb5560-bcf8-414d-bb06-335e7c15e61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE CLEANUP SCRIPT\n",
      "================================================================================\n",
      "\n",
      "[1/4] Loading diagnostic report...\n",
      "âœ… Loaded report with 232 features\n",
      "\n",
      "[2/4] Generating removal summary...\n",
      "\n",
      "================================================================================\n",
      "FEATURE REMOVAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ HIGH PRIORITY REMOVALS (Clear Garbage):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. vix_extreme_low_21d                      â†’ too few unique values\n",
      "     âš ï¸  Zeros: 81.5%\n",
      "     âš ï¸  Unique values: 2\n",
      "  2. vix_term_structure                       â†’ missing 100.0%, no variance, too few unique values\n",
      "     âš ï¸  Missing: 100.0%\n",
      "     âš ï¸  Unique values: 0\n",
      "  3. vol_term_regime                          â†’ zero 100.0%, no variance, too few unique values\n",
      "     âš ï¸  Zeros: 100.0%\n",
      "     âš ï¸  Unique values: 1\n",
      "  4. vix_extreme_low_63d                      â†’ too few unique values\n",
      "     âš ï¸  Zeros: 78.7%\n",
      "     âš ï¸  Unique values: 2\n",
      "  5. vix_extreme_low_252d                     â†’ too few unique values\n",
      "     âš ï¸  Zeros: 82.4%\n",
      "     âš ï¸  Unique values: 2\n",
      "  6. SKEW_extreme_low_63d                     â†’ too few unique values\n",
      "     âš ï¸  Zeros: 89.5%\n",
      "     âš ï¸  Unique values: 2\n",
      "  7. SKEW_extreme_low_252d                    â†’ too few unique values\n",
      "     âš ï¸  Zeros: 92.1%\n",
      "     âš ï¸  Unique values: 2\n",
      "  8. risk_premium_extreme_low_63d             â†’ too few unique values\n",
      "     âš ï¸  Zeros: 85.6%\n",
      "     âš ï¸  Unique values: 2\n",
      "  9. risk_premium_extreme_low_252d            â†’ too few unique values\n",
      "     âš ï¸  Zeros: 89.3%\n",
      "     âš ï¸  Unique values: 2\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ MEDIUM PRIORITY REMOVALS (Redundant Features):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… KEEP: vix\n",
      "   âŒ REMOVE: VXTLT                                    (corr: 0.951)\n",
      "\n",
      "âœ… KEEP: vix_bb_position_20d\n",
      "   âŒ REMOVE: vix_zscore_21d                           (corr: 0.986)\n",
      "   âŒ REMOVE: vix_percentile_21d                       (corr: 0.966)\n",
      "\n",
      "âœ… KEEP: yield_10y2y\n",
      "   âŒ REMOVE: yield_5y2y                               (corr: 0.969)\n",
      "\n",
      "âœ… KEEP: yield_10y2y_zscore\n",
      "   âŒ REMOVE: yield_10y2y_percentile_252d              (corr: 0.973)\n",
      "\n",
      "âœ… KEEP: yield_10y3m\n",
      "   âŒ REMOVE: yield_5y2y                               (corr: 0.964)\n",
      "\n",
      "âœ… KEEP: dgs10_vol_63d\n",
      "   âŒ REMOVE: yield_curve_vol_avg                      (corr: 0.952)\n",
      "\n",
      "âœ… KEEP: risk_premium_percentile_126d\n",
      "   âŒ REMOVE: risk_premium_percentile_252d             (corr: 0.965)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ… Summary saved to: ./diagnostics/removal_summary.txt\n",
      "\n",
      "[3/4] Identifying features to remove...\n",
      "\n",
      "ğŸ—‘ï¸  Removing 16 features:\n",
      "   High Priority (garbage):  9\n",
      "   Medium Priority (redundant): 8\n",
      "\n",
      "ğŸ“Š Final counts:\n",
      "   Original features: 232\n",
      "   Features to REMOVE: 16\n",
      "   Features to KEEP: 223\n",
      "   After cleanup: 223 features (96.1% of original)\n",
      "\n",
      "[4/4] Generating cleaned config...\n",
      "\n",
      "âš ï¸  WARNING: Automatic config generation is complex.\n",
      "   Instead, I'll generate a Python script that you can review.\n",
      "   The safest approach is to manually remove features from config.py\n",
      "\n",
      "âœ… Saved removal list to: ./diagnostics/features_to_remove.json\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS:\n",
      "================================================================================\n",
      "\n",
      "1. Review the removal summary:\n",
      "   cat ./diagnostics/removal_summary.txt\n",
      "\n",
      "2. Review the features to remove:\n",
      "   cat ./diagnostics/features_to_remove.json\n",
      "\n",
      "3. Manually edit config.py to remove these features from:\n",
      "   - VIX_BASE_FEATURES\n",
      "   - SPX_BASE_FEATURES\n",
      "   - CBOE_BASE_FEATURES\n",
      "   - FUTURES_FEATURES\n",
      "   - META_FEATURES\n",
      "   - ANOMALY_FEATURE_GROUPS\n",
      "\n",
      "4. Re-run training to verify:\n",
      "   python integrated_system_production.py\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Feature Cleanup Script - Auto-generate cleaned config.py\n",
    "\n",
    "This script:\n",
    "1. Reads your diagnostic report\n",
    "2. Identifies features to remove (high priority + medium priority)\n",
    "3. Generates a new config.py with cleaned feature groups\n",
    "4. Backs up your old config.py\n",
    "\n",
    "Usage:\n",
    "    python feature_cleanup.py\n",
    "\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "\n",
    "def load_diagnostic_report(path='./diagnostics/feature_report.json'):\n",
    "    \"\"\"Load the diagnostic report.\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def get_features_to_remove(report):\n",
    "    \"\"\"Extract all features that should be removed.\"\"\"\n",
    "    remove_set = set()\n",
    "    \n",
    "    # High priority removals (clear garbage)\n",
    "    for item in report['recommendations']['remove_high_priority']:\n",
    "        remove_set.add(item['feature'])\n",
    "    \n",
    "    # Medium priority removals (redundant)\n",
    "    for item in report['recommendations']['remove_medium_priority']:\n",
    "        remove_set.add(item['feature'])\n",
    "    \n",
    "    # Note: We keep manual review items for now (only 1 feature)\n",
    "    # You can add them here if you want: SKEW_momentum_regime\n",
    "    \n",
    "    print(f\"\\nğŸ—‘ï¸  Removing {len(remove_set)} features:\")\n",
    "    print(f\"   High Priority (garbage):  {len(report['recommendations']['remove_high_priority'])}\")\n",
    "    print(f\"   Medium Priority (redundant): {len(report['recommendations']['remove_medium_priority'])}\")\n",
    "    \n",
    "    return remove_set\n",
    "\n",
    "\n",
    "def clean_feature_group(feature_list, remove_set):\n",
    "    \"\"\"Remove problematic features from a feature group.\"\"\"\n",
    "    return [f for f in feature_list if f not in remove_set]\n",
    "\n",
    "\n",
    "def generate_cleaned_config(report, output_path='./config_cleaned.py'):\n",
    "    \"\"\"Generate a new config.py with cleaned feature groups.\"\"\"\n",
    "    \n",
    "    remove_set = get_features_to_remove(report)\n",
    "    \n",
    "    # Read original config.py\n",
    "    with open('./config.py', 'r') as f:\n",
    "        original_config = f.read()\n",
    "    \n",
    "    # Start building the new config\n",
    "    lines = []\n",
    "    lines.append('\"\"\"Enhanced Configuration V4 - AUTO-CLEANED\"\"\"')\n",
    "    lines.append('# Generated automatically by feature_cleanup.py')\n",
    "    lines.append(f'# Timestamp: {datetime.now().isoformat()}')\n",
    "    lines.append(f'# Removed {len(remove_set)} problematic features')\n",
    "    lines.append('')\n",
    "    lines.append('from pathlib import Path')\n",
    "    lines.append('')\n",
    "    \n",
    "    # Copy everything up to feature definitions\n",
    "    config_lines = original_config.split('\\n')\n",
    "    in_feature_section = False\n",
    "    \n",
    "    for line in config_lines:\n",
    "        # Copy header sections\n",
    "        if 'VIX_BASE_FEATURES' in line:\n",
    "            in_feature_section = True\n",
    "        \n",
    "        if not in_feature_section:\n",
    "            # Skip the docstring since we replaced it\n",
    "            if line.startswith('\"\"\"Enhanced Configuration V4\"\"\"'):\n",
    "                continue\n",
    "            lines.append(line)\n",
    "    \n",
    "    # Now manually rebuild feature definitions with cleaning\n",
    "    lines.append('# Feature Definitions - VIX Base')\n",
    "    lines.append('VIX_BASE_FEATURES = {')\n",
    "    lines.append(\"    'mean_reversion': [\")\n",
    "    \n",
    "    # Define original feature groups (you'll need to extract these from config.py)\n",
    "    # For now, I'll create a template you can fill in\n",
    "    \n",
    "    vix_mean_reversion = [\n",
    "        'vix_vs_ma10', 'vix_vs_ma21', 'vix_vs_ma63', 'vix_vs_ma252',\n",
    "        'vix_bb_position_20d', 'reversion_strength_21d', 'reversion_strength_63d',\n",
    "        'vix_pull_ma21', 'vix_pull_ma63', 'vix_stretch_ma21', 'vix_stretch_ma63',\n",
    "        'vix_extreme_low_21d', 'vix_extreme_high_21d', 'vix_mean_distance_21d'\n",
    "    ]\n",
    "    \n",
    "    cleaned = clean_feature_group(vix_mean_reversion, remove_set)\n",
    "    for feat in cleaned:\n",
    "        lines.append(f\"        '{feat}',\")\n",
    "    lines.append(\"    ],\")\n",
    "    \n",
    "    # ... continue for all feature groups\n",
    "    \n",
    "    lines.append('}')\n",
    "    lines.append('')\n",
    "    \n",
    "    # Write the new config\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('\\n'.join(lines))\n",
    "    \n",
    "    print(f\"\\nâœ… Generated cleaned config: {output_path}\")\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"1. Review {output_path}\")\n",
    "    print(f\"2. If satisfied, backup and replace:\")\n",
    "    print(f\"   cp config.py config_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py\")\n",
    "    print(f\"   mv {output_path} config.py\")\n",
    "    print(f\"3. Re-run training: python integrated_system_production.py\")\n",
    "\n",
    "\n",
    "def generate_removal_summary(report):\n",
    "    \"\"\"Generate a detailed summary of what's being removed and why.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE REMOVAL SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nğŸ“‹ HIGH PRIORITY REMOVALS (Clear Garbage):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, item in enumerate(report['recommendations']['remove_high_priority'], 1):\n",
    "        reasons = ', '.join(item['reasons'])\n",
    "        print(f\"{i:3d}. {item['feature']:40s} â†’ {reasons}\")\n",
    "        \n",
    "        # Show metrics\n",
    "        metrics = item['metrics']\n",
    "        if metrics['missing_pct'] > 50:\n",
    "            print(f\"     âš ï¸  Missing: {metrics['missing_pct']:.1f}%\")\n",
    "        if metrics['zero_pct'] > 50:\n",
    "            print(f\"     âš ï¸  Zeros: {metrics['zero_pct']:.1f}%\")\n",
    "        if metrics['unique_values'] < 3:\n",
    "            print(f\"     âš ï¸  Unique values: {metrics['unique_values']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\\nğŸ“‹ MEDIUM PRIORITY REMOVALS (Redundant Features):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Group by redundancy pairs\n",
    "    redundancy_map = {}\n",
    "    for item in report['recommendations']['remove_medium_priority']:\n",
    "        reasons = item['reasons'][0] if item['reasons'] else 'unknown'\n",
    "        if 'redundant with' in reasons:\n",
    "            kept_feature = reasons.split('redundant with ')[1]\n",
    "            if kept_feature not in redundancy_map:\n",
    "                redundancy_map[kept_feature] = []\n",
    "            redundancy_map[kept_feature].append({\n",
    "                'removed': item['feature'],\n",
    "                'correlation': item.get('correlation', 0.0)\n",
    "            })\n",
    "    \n",
    "    for kept, removed_list in redundancy_map.items():\n",
    "        print(f\"\\nâœ… KEEP: {kept}\")\n",
    "        for r in removed_list:\n",
    "            print(f\"   âŒ REMOVE: {r['removed']:40s} (corr: {r['correlation']:.3f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Save to file\n",
    "    summary_path = './diagnostics/removal_summary.txt'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"FEATURE REMOVAL SUMMARY\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().isoformat()}\\n\")\n",
    "        f.write(f\"Total features to remove: {len(report['recommendations']['remove_high_priority']) + len(report['recommendations']['remove_medium_priority'])}\\n\\n\")\n",
    "        \n",
    "        f.write(\"HIGH PRIORITY REMOVALS:\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for i, item in enumerate(report['recommendations']['remove_high_priority'], 1):\n",
    "            f.write(f\"{i:3d}. {item['feature']:40s} â†’ {', '.join(item['reasons'])}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nMEDIUM PRIORITY REMOVALS:\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for kept, removed_list in redundancy_map.items():\n",
    "            f.write(f\"\\nKEEP: {kept}\\n\")\n",
    "            for r in removed_list:\n",
    "                f.write(f\"  REMOVE: {r['removed']:40s} (corr: {r['correlation']:.3f})\\n\")\n",
    "    \n",
    "    print(f\"\\nâœ… Summary saved to: {summary_path}\")\n",
    "\n",
    "\n",
    "def backup_config():\n",
    "    \"\"\"Backup the current config.py.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    backup_path = f'./config_backup_{timestamp}.py'\n",
    "    shutil.copy('./config.py', backup_path)\n",
    "    print(f\"\\nâœ… Backed up config.py to {backup_path}\")\n",
    "    return backup_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE CLEANUP SCRIPT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load diagnostic report\n",
    "    print(\"\\n[1/4] Loading diagnostic report...\")\n",
    "    try:\n",
    "        report = load_diagnostic_report()\n",
    "        print(f\"âœ… Loaded report with {report['total_features']} features\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Error: diagnostics/feature_report.json not found\")\n",
    "        print(\"   Run this first: python integrated_system_production.py\")\n",
    "        return\n",
    "    \n",
    "    # Generate removal summary\n",
    "    print(\"\\n[2/4] Generating removal summary...\")\n",
    "    generate_removal_summary(report)\n",
    "    \n",
    "    # Get features to remove\n",
    "    print(\"\\n[3/4] Identifying features to remove...\")\n",
    "    remove_set = get_features_to_remove(report)\n",
    "    \n",
    "    # Show what we're keeping\n",
    "    keep_count = len(report['recommendations']['keep'])\n",
    "    remove_count = len(remove_set)\n",
    "    print(f\"\\nğŸ“Š Final counts:\")\n",
    "    print(f\"   Original features: {report['total_features']}\")\n",
    "    print(f\"   Features to REMOVE: {remove_count}\")\n",
    "    print(f\"   Features to KEEP: {keep_count}\")\n",
    "    print(f\"   After cleanup: {keep_count} features ({keep_count/report['total_features']*100:.1f}% of original)\")\n",
    "    \n",
    "    # Generate cleaned config\n",
    "    print(\"\\n[4/4] Generating cleaned config...\")\n",
    "    print(\"\\nâš ï¸  WARNING: Automatic config generation is complex.\")\n",
    "    print(\"   Instead, I'll generate a Python script that you can review.\")\n",
    "    print(\"   The safest approach is to manually remove features from config.py\")\n",
    "    \n",
    "    # Save removal list\n",
    "    removal_list_path = './diagnostics/features_to_remove.json'\n",
    "    with open(removal_list_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'features_to_remove': sorted(list(remove_set)),\n",
    "            'count': len(remove_set),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ… Saved removal list to: {removal_list_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n1. Review the removal summary:\")\n",
    "    print(\"   cat ./diagnostics/removal_summary.txt\")\n",
    "    print(\"\\n2. Review the features to remove:\")\n",
    "    print(\"   cat ./diagnostics/features_to_remove.json\")\n",
    "    print(\"\\n3. Manually edit config.py to remove these features from:\")\n",
    "    print(\"   - VIX_BASE_FEATURES\")\n",
    "    print(\"   - SPX_BASE_FEATURES\")\n",
    "    print(\"   - CBOE_BASE_FEATURES\")\n",
    "    print(\"   - FUTURES_FEATURES\")\n",
    "    print(\"   - META_FEATURES\")\n",
    "    print(\"   - ANOMALY_FEATURE_GROUPS\")\n",
    "    print(\"\\n4. Re-run training to verify:\")\n",
    "    print(\"   python integrated_system_production.py\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d14ac6af-c080-4370-9660-c3a039d41af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Found 20 CSV files in CBOE_Data_Archive\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ (VX2-VX1)OVER(VX1).csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 5443 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date      Open      High       Low     Close\n",
      "2004-03-26 -0.042844 -0.007874 -0.042844 -0.007874\n",
      "2004-03-29 -0.002513 -0.001013 -0.007004 -0.001515\n",
      "2004-03-30 -0.000504  0.008665 -0.007984  0.008665\n",
      "2004-03-31  0.015760  0.015760  0.005063  0.005063\n",
      "2004-04-01  0.003523  0.003523 -0.002501 -0.000510\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ BFLY.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2569 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date   Open   High    Low  Close\n",
      "2015-08-17 540.96 551.19 539.46 550.70\n",
      "2015-08-18 549.61 551.63 547.47 548.57\n",
      "2015-08-19 542.99 548.42 534.85 540.48\n",
      "2015-08-20 530.42 533.70 513.16 517.56\n",
      "2015-08-21 507.43 507.43 507.43 507.43\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ BVOL.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 3444 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "2016-05-02 22.84 22.84 22.84  22.84\n",
      "2016-05-03 22.84 24.11 22.84  24.11\n",
      "2016-05-04 24.11 24.30 24.11  24.30\n",
      "2016-05-05 24.30 24.38 24.30  24.38\n",
      "2016-05-06 24.38 24.38 24.32  24.32\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ CL1-CL2.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 9999 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "1986-02-03  0.10  0.10 -0.78  -0.47\n",
      "1986-02-04 -0.32 -0.20 -0.98  -0.89\n",
      "1986-02-05  0.18  0.18 -0.22  -0.22\n",
      "1986-02-06 -0.05 -0.05 -0.30  -0.22\n",
      "1986-02-07 -0.25  0.18 -0.25   0.02\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ CNDR_SPX_IRON_CONDOR_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 9916 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "1986-06-20 100.0 100.0 100.0  100.0\n",
      "1986-06-23 100.0 100.0 100.0  100.0\n",
      "1986-06-24 100.0 100.0 100.0  100.0\n",
      "1986-06-25 100.0 100.0 100.0  100.0\n",
      "1986-06-26 100.0 100.0 100.0  100.0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ COR1M_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2747 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date      Open      High   Low  Close\n",
      "2014-11-20 39.881136 39.881136 38.71  38.71\n",
      "2014-11-21 39.295568 39.295568 35.18  35.18\n",
      "2014-11-24 37.237784 37.237784 34.84  34.84\n",
      "2014-11-25 36.038892 36.038892 34.21  34.21\n",
      "2014-11-26 35.124446 35.124446 33.93  33.93\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ COR3M_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2731 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date      Open  High       Low  Close\n",
      "2014-12-08 38.496454 40.38 38.496454  40.38\n",
      "2014-12-09 39.438227 39.84 39.438227  39.84\n",
      "2014-12-10 39.639113 46.26 39.639113  46.26\n",
      "2014-12-11 42.949557 50.99 42.949557  50.99\n",
      "2014-12-12 46.969778 51.63 46.969778  51.63\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ DSPX.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2834 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "2014-07-31 15.10 15.10 15.10  15.10\n",
      "2014-08-01 16.16 16.16 16.16  16.16\n",
      "2014-08-04 17.36 17.36 17.36  17.36\n",
      "2014-08-05 16.85 16.85 16.85  16.85\n",
      "2014-08-06 17.50 17.50 17.50  17.50\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ DX1-DX2.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 10001 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "1986-05-09 -0.10 -0.05 -0.27  -0.12\n",
      "1986-05-12 -0.05 -0.05 -0.10  -0.10\n",
      "1986-05-13 -0.15  0.02 -0.15   0.02\n",
      "1986-05-14 -0.30  0.00 -0.30  -0.12\n",
      "1986-05-15 -0.13 -0.10 -0.23  -0.12\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ GAMMA.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 727 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date     Open     High      Low    Close\n",
      "2022-12-12 648.7817 658.1320 648.7784 657.9655\n",
      "2022-12-13 662.2339 664.5887 631.7707 633.4854\n",
      "2022-12-14 629.9458 635.0857 611.7991 612.2024\n",
      "2022-12-15 616.0346 656.4181 614.4316 640.2184\n",
      "2022-12-16 641.5310 648.3331 637.6603 641.6960\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ GOLDSILVER_RATIO.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2864 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date      Open   High       Low    Close\n",
      "2014-10-29 71.263126 73.108 70.534000 71.79050\n",
      "2014-10-30 71.526813 73.391 71.526813 72.79425\n",
      "2014-11-02 72.160532 73.560 72.134000 72.60325\n",
      "2014-11-03 72.381891 73.168 72.118000 72.56300\n",
      "2014-11-04 72.472445 75.145 72.472445 73.76775\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ PCCE_EQUITIES_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2805 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date     Open  High   Low   Close\n",
      "2014-10-22 0.916613 1.062 0.553 0.90375\n",
      "2014-10-23 0.910181 0.983 0.793 0.90275\n",
      "2014-10-24 0.906466 0.943 0.770 0.85325\n",
      "2014-10-27 0.879858 1.528 0.825 1.15600\n",
      "2014-10-28 1.017929 1.528 0.558 1.11175\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ PCCI_INDX_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2776 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date     Open  High      Low   Close\n",
      "2014-10-03 1.026260 1.280 0.779000 1.06875\n",
      "2014-10-06 1.047505 1.504 0.550000 0.93825\n",
      "2014-10-07 0.992877 1.040 0.654000 0.93500\n",
      "2014-10-08 0.963939 1.567 0.963939 1.29275\n",
      "2014-10-09 1.128344 1.197 0.582000 0.93225\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ PCC_INDX_EQ_TOTAL_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2778 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date     Open     High   Low   Close\n",
      "2014-10-20 1.129123 1.129123 0.745 0.90275\n",
      "2014-10-21 1.015937 1.043000 0.697 0.92600\n",
      "2014-10-22 0.970968 1.145000 0.697 0.98050\n",
      "2014-10-23 0.975734 1.014000 0.760 0.89800\n",
      "2014-10-24 0.936867 1.064000 0.823 0.92400\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ SKEW_INDEX_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2743 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date       Open       High        Low  Close\n",
      "2014-10-27 126.694763 126.694763 123.770000 123.77\n",
      "2014-10-28 125.232381 127.560000 125.232381 127.56\n",
      "2014-10-29 126.396191 126.396191 124.180000 124.18\n",
      "2014-10-30 125.288095 125.288095 121.020000 121.02\n",
      "2014-10-31 123.154048 124.750000 123.154048 124.75\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ VIXoverVIX3M.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 4530 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date     Open     High      Low    Close\n",
      "2007-12-05 0.969781 0.987141 0.937420 0.966031\n",
      "2007-12-06 0.967906 1.029412 0.889140 0.973303\n",
      "2007-12-07 0.970604 0.970604 0.914788 0.933724\n",
      "2007-12-10 0.952164 0.978569 0.928408 0.954400\n",
      "2007-12-11 0.953282 0.982587 0.819651 0.909515\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ VPN.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 4455 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date   Open   High    Low  Close\n",
      "2004-06-15 100.00 100.00 100.00 100.00\n",
      "2004-06-16 100.03 100.03 100.03 100.03\n",
      "2004-06-17 100.00 100.00 100.00 100.00\n",
      "2004-06-18 100.14 100.14 100.14 100.14\n",
      "2004-06-21  99.89  99.89  99.89  99.89\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ VX1-VX2.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 5434 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date  Open  High   Low  Close\n",
      "2004-04-06 -0.25  0.03 -0.25   0.00\n",
      "2004-04-07  0.02  0.03 -0.06  -0.03\n",
      "2004-04-08 -0.30  0.05 -0.30   0.05\n",
      "2004-04-12  0.03  0.03 -0.24  -0.23\n",
      "2004-04-13  0.15  0.15  0.00   0.01\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ VXTH_TAILHEDGE_CBOE.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 2766 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date       Open   High        Low    Close\n",
      "2014-10-24 182.095405 185.07 182.095405 184.3550\n",
      "2014-10-27 183.225203 184.92 183.225203 184.4975\n",
      "2014-10-28 183.861351 186.11 183.861351 185.4325\n",
      "2014-10-29 184.646926 186.63 184.646926 185.8750\n",
      "2014-10-30 185.260963 187.28 185.260963 186.3075\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ VXTLT.csv\n",
      "--------------------------------------------------------------------------------\n",
      "Shape: 9002 rows Ã— 5 columns\n",
      "Columns: Date, Open, High, Low, Close\n",
      "\n",
      "Top 5 entries:\n",
      "      Date      Open      High       Low  Close\n",
      "1990-03-16 19.460983 19.460983 17.620000  17.62\n",
      "1990-03-19 18.540492 18.540492 18.290000  18.29\n",
      "1990-03-20 18.415246 19.060000 18.415246  19.06\n",
      "1990-03-21 18.737623 20.100000 18.737623  20.10\n",
      "1990-03-22 19.418811 22.740000 19.418811  22.74\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick script to show the top 5 entries of every CSV file in CBOE_Data_Archive\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def preview_cboe_files():\n",
    "    # Get the CBOE_Data_Archive directory relative to current location\n",
    "    cboe_dir = Path(\"CBOE_Data_Archive\")\n",
    "    \n",
    "    if not cboe_dir.exists():\n",
    "        print(f\"âŒ Directory not found: {cboe_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Get all CSV files\n",
    "    csv_files = sorted(cboe_dir.glob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"âŒ No CSV files found in {cboe_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“Š Found {len(csv_files)} CSV files in CBOE_Data_Archive\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nğŸ“ {csv_file.name}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Show info\n",
    "            print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "            print(f\"Columns: {', '.join(df.columns.tolist())}\")\n",
    "            print(f\"\\nTop 5 entries:\")\n",
    "            print(df.head(5).to_string(index=False))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Error reading file: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preview_cboe_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8442ff5-21d4-4655-a88f-190fa8e2a084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

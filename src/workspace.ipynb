{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ce1c471-c980-4074-98bc-df9c7e3ce1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Technical diagnostic report saved: ./docs/TECHNICAL_DIAGNOSTIC.md\n",
      "   Issues found: 0\n",
      "   Warnings: 0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# üîß Technical System Diagnostic Report\n",
       "\n",
       "*Generated: 2025-11-07 22:06:43*\n",
       "*Quick Mode: OFF*\n",
       "\n",
       "---\n",
       "\n",
       "## 1. üè• System Health Check\n",
       "\n",
       "**Overall Status**: ‚úÖ HEALTHY\n",
       "\n",
       "### Component Status\n",
       "| Component | Status | Details |\n",
       "|-----------|--------|---------|\n",
       "| data | ‚úÖ | 3769 rows |\n",
       "| model | ‚úÖ | Trained |\n",
       "| detector_coverage | ‚úÖ | 0 detectors with <70% coverage |\n",
       "| data_freshness | ‚úÖ | 3 days old |\n",
       "| data_completeness | ‚úÖ | 79.1% complete |\n",
       "\n",
       "## 2. üéõÔ∏è Model Configuration Deep Dive\n",
       "\n",
       "### Anomaly Detector Configuration\n",
       "```python\n",
       "contamination: 0.050\n",
       "n_estimators: 100\n",
       "max_samples: auto\n",
       "random_state: 42\n",
       "```\n",
       "\n",
       "### Individual Detector Parameters\n",
       "| Detector | Features Used | Coverage | Active |\n",
       "|----------|--------------|----------|--------|\n",
       "| vix_mean_reversion | 18 | 100.0% | ‚úÖ |\n",
       "| vix_momentum | 18 | 100.0% | ‚úÖ |\n",
       "| vix_regime_structure | 18 | 100.0% | ‚úÖ |\n",
       "| cboe_options_flow | 39 | 100.0% | ‚úÖ |\n",
       "| cboe_cross_dynamics | 17 | 100.0% | ‚úÖ |\n",
       "| vix_spx_relationship | 17 | 100.0% | ‚úÖ |\n",
       "| spx_price_action | 15 | 75.0% | ‚úÖ |\n",
       "| spx_volatility_regime | 20 | 90.9% | ‚úÖ |\n",
       "| cross_asset_divergence | 23 | 88.5% | ‚úÖ |\n",
       "| tail_risk_complex | 15 | 83.3% | ‚úÖ |\n",
       "| futures_term_structure | 27 | 100.0% | ‚úÖ |\n",
       "| macro_regime_shifts | 19 | 100.0% | ‚úÖ |\n",
       "| momentum_acceleration | 20 | 100.0% | ‚úÖ |\n",
       "| percentile_extremes | 19 | 100.0% | ‚úÖ |\n",
       "| random_4 | 0 | 0.0% | ‚úÖ |\n",
       "\n",
       "## 3. üîÑ Data Pipeline Flow Trace\n",
       "\n",
       "### Data Sources ‚Üí Features ‚Üí Models\n",
       "```\n",
       "Data Fetching...........................       ‚úÖ OK\n",
       "  ‚Ü≥ VIX: 3769 observations\n",
       "  ‚Ü≥ SPX: 3769 observations\n",
       "Feature Engineering.....................       ‚úÖ OK\n",
       "  ‚Ü≥ Generated 696 features\n",
       "  ‚Ü≥ Time period: 3769 days\n",
       "Model Training..........................       ‚úÖ OK\n",
       "  ‚Ü≥ 15/15 detectors trained\n",
       "  ‚Ü≥ Ensemble scores computed: 3769\n",
       "```\n",
       "\n",
       "### Feature Generation Summary\n",
       "- **Raw Market Data Points**: 7538\n",
       "- **Engineered Features**: 696\n",
       "- **Final Feature Set**: 696\n",
       "- **Data Reduction Ratio**: 0.1x\n",
       "\n",
       "## 4. üìÖ Data Freshness & Staleness\n",
       "\n",
       "### Last Update Times\n",
       "| Data Source | Last Update | Age (days) | Status |\n",
       "|-------------|-------------|------------|--------|\n",
       "| Main Features | 2025-11-04 | 3.9 | ‚ùå |\n",
       "\n",
       "### ‚ö†Ô∏è Stale Features (>5% missing in recent data)\n",
       "- **SKEW**: 100.0% missing\n",
       "- **SKEW_change_21d**: 100.0% missing\n",
       "- **SKEW_zscore_63d**: 100.0% missing\n",
       "- **PCCI**: 100.0% missing\n",
       "- **PCCI_change_21d**: 100.0% missing\n",
       "- **PCCI_zscore_63d**: 100.0% missing\n",
       "- **PCCE**: 100.0% missing\n",
       "- **PCCE_change_21d**: 100.0% missing\n",
       "- **PCCE_zscore_63d**: 100.0% missing\n",
       "- **PCC**: 100.0% missing\n",
       "\n",
       "## 5. üéØ Current Anomaly Detection Breakdown\n",
       "\n",
       "### Ensemble Score: 38.1%\n",
       "\n",
       "### Detector Contributions\n",
       "| Detector | Score | Weight | Weighted Score | Agreement |\n",
       "|----------|-------|--------|----------------|-----------|\n",
       "| spx_price_action | 81.1% | 1.00 | 81.1% | üî¥ |\n",
       "| tail_risk_complex | 79.9% | 1.00 | 79.9% | üî¥ |\n",
       "| spx_volatility_regime | 59.1% | 1.00 | 59.1% | üî¥ |\n",
       "| vix_momentum | 55.8% | 1.00 | 55.8% | üü¢ |\n",
       "| vix_regime_structure | 52.0% | 1.00 | 52.0% | üü¢ |\n",
       "| percentile_extremes | 43.4% | 1.00 | 43.4% | üü¢ |\n",
       "| cross_asset_divergence | 38.4% | 1.00 | 38.4% | üü¢ |\n",
       "| vix_mean_reversion | 37.9% | 1.00 | 37.9% | üü¢ |\n",
       "| vix_spx_relationship | 31.3% | 1.00 | 31.3% | üü¢ |\n",
       "| macro_regime_shifts | 13.4% | 1.00 | 13.4% | üî¥ |\n",
       "| momentum_acceleration | 8.2% | 1.00 | 8.2% | üî¥ |\n",
       "| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | üî¥ |\n",
       "| futures_term_structure | 5.4% | 1.00 | 5.4% | üî¥ |\n",
       "| cboe_options_flow | 1.5% | 1.00 | 1.5% | üî¥ |\n",
       "\n",
       "### Top Features Driving Current Anomaly\n",
       "| Feature | Importance | Current Value | Z-Score |\n",
       "|---------|-----------|---------------|---------|\n",
       "| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\n",
       "| spx_lag1 | 0.088 | 6851.97 | 2.70 |\n",
       "| spx_ret_5d | 0.082 | -1.73 | -0.89 |\n",
       "| spx_lag5 | 0.082 | 6890.89 | 2.74 |\n",
       "| spx_ret_13d | 0.075 | 2.15 | 0.43 |\n",
       "| spx_ret_63d | 0.070 | 6.72 | 0.54 |\n",
       "| rsi_14 | 0.067 | 59.06 | 0.14 |\n",
       "| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\n",
       "| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\n",
       "| bb_width_20d | 0.058 | 5.64 | -0.13 |\n",
       "\n",
       "## 6. üîó Feature Correlation & Redundancy Analysis\n",
       "\n",
       "### High Correlation Pairs (>95%)\n",
       "| Feature 1 | Feature 2 | Correlation |\n",
       "|-----------|-----------|-------------|\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\n",
       "\n",
       "**Recommendation**: Consider removing 17552 redundant features to improve performance.\n",
       "\n",
       "## 7. ‚ö° Performance Profiling\n",
       "\n",
       "### Execution Time Breakdown\n",
       "| Operation | Time (ms) | % of Total |\n",
       "|-----------|-----------|------------|\n",
       "| batch_10_detections | 168.6 | 89.7% |\n",
       "| single_detection | 19.3 | 10.3% |\n",
       "\n",
       "## 8. üîç Common Failure Modes & Solutions\n",
       "\n",
       "‚úÖ No common failure modes detected.\n",
       "\n",
       "## 9. üí° What-If Scenario Analysis\n",
       "\n",
       "### VIX Spike to 40\n",
       "**Scenario**: If VIX suddenly spikes to 40 (crisis level)\n",
       "**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\n",
       "**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\n",
       "\n",
       "### SKEW >150\n",
       "**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\n",
       "**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\n",
       "**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\n",
       "\n",
       "### All CBOE Data Missing\n",
       "**Scenario**: If CBOE features become unavailable\n",
       "**Expected Behavior**: System continues to function with reduced capability\n",
       "**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\n",
       "\n",
       "## 10. üìä Data Quality Heatmap\n",
       "\n",
       "### Feature Quality by Category\n",
       "| Category | Total Features | Complete | Sparse | Missing | Quality Score |\n",
       "|----------|---------------|----------|--------|---------|---------------|\n",
       "| VIX | 78 | 73 | 0 | 5 | 93.6% |\n",
       "| SPX | 47 | 44 | 0 | 3 | 93.6% |\n",
       "| CBOE | 232 | 24 | 33 | 175 | 17.5% |\n",
       "| Futures | 45 | 35 | 10 | 0 | 88.9% |\n",
       "| Macro | 14 | 11 | 1 | 2 | 82.1% |\n",
       "| Meta | 280 | 84 | 122 | 74 | 51.8% |\n",
       "\n",
       "## 11. üöÄ System Optimization Recommendations\n",
       "\n",
       "### üü¢ Optimization Opportunities\n",
       "- Remove 17552 highly correlated features to reduce redundancy\n",
       "- Investigate 197 stale features with high recent missing data\n",
       "- Consider adding feature selection to reduce dimensionality\n",
       "- Implement caching for expensive feature calculations\n",
       "- Add monitoring alerts for data freshness\n",
       "\n",
       "## 12. üìñ Quick Reference: Troubleshooting Guide\n",
       "\n",
       "\n",
       "### Common Issues & Quick Fixes\n",
       "\n",
       "**Issue**: System says \"data too old\"\n",
       "- **Check**: `system.orchestrator.features.index[-1]`\n",
       "- **Fix**: Run `system.refresh()` or retrain with fresh data\n",
       "\n",
       "**Issue**: Ensemble score always near 0% or 100%\n",
       "- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\n",
       "- **Fix**: Retrain system to recalculate thresholds\n",
       "\n",
       "**Issue**: Many detectors show 0% coverage\n",
       "- **Check**: CBOE files in `./CBOE_Data_Archive/`\n",
       "- **Fix**: Download CBOE historical data or disable CBOE features in config\n",
       "\n",
       "**Issue**: \"Core data fetch failed\" error\n",
       "- **Check**: Internet connection, yfinance API status\n",
       "- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\n",
       "\n",
       "**Issue**: High memory usage\n",
       "- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\n",
       "- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\n",
       "\n",
       "**Issue**: Slow detection speed (>1 second)\n",
       "- **Check**: Number of features and detectors active\n",
       "- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\n",
       "\n",
       "**Issue**: NaN/Inf values in features\n",
       "- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\n",
       "- **Fix**: Review feature_engine.py for division by zero or missing data handling\n",
       "\n",
       "\n",
       "---\n",
       "*Report generated in 2.34 seconds*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'# üîß Technical System Diagnostic Report\\n\\n*Generated: 2025-11-07 22:06:43*\\n*Quick Mode: OFF*\\n\\n---\\n\\n## 1. üè• System Health Check\\n\\n**Overall Status**: ‚úÖ HEALTHY\\n\\n### Component Status\\n| Component | Status | Details |\\n|-----------|--------|---------|\\n| data | ‚úÖ | 3769 rows |\\n| model | ‚úÖ | Trained |\\n| detector_coverage | ‚úÖ | 0 detectors with <70% coverage |\\n| data_freshness | ‚úÖ | 3 days old |\\n| data_completeness | ‚úÖ | 79.1% complete |\\n\\n## 2. üéõÔ∏è Model Configuration Deep Dive\\n\\n### Anomaly Detector Configuration\\n```python\\ncontamination: 0.050\\nn_estimators: 100\\nmax_samples: auto\\nrandom_state: 42\\n```\\n\\n### Individual Detector Parameters\\n| Detector | Features Used | Coverage | Active |\\n|----------|--------------|----------|--------|\\n| vix_mean_reversion | 18 | 100.0% | ‚úÖ |\\n| vix_momentum | 18 | 100.0% | ‚úÖ |\\n| vix_regime_structure | 18 | 100.0% | ‚úÖ |\\n| cboe_options_flow | 39 | 100.0% | ‚úÖ |\\n| cboe_cross_dynamics | 17 | 100.0% | ‚úÖ |\\n| vix_spx_relationship | 17 | 100.0% | ‚úÖ |\\n| spx_price_action | 15 | 75.0% | ‚úÖ |\\n| spx_volatility_regime | 20 | 90.9% | ‚úÖ |\\n| cross_asset_divergence | 23 | 88.5% | ‚úÖ |\\n| tail_risk_complex | 15 | 83.3% | ‚úÖ |\\n| futures_term_structure | 27 | 100.0% | ‚úÖ |\\n| macro_regime_shifts | 19 | 100.0% | ‚úÖ |\\n| momentum_acceleration | 20 | 100.0% | ‚úÖ |\\n| percentile_extremes | 19 | 100.0% | ‚úÖ |\\n| random_4 | 0 | 0.0% | ‚úÖ |\\n\\n## 3. üîÑ Data Pipeline Flow Trace\\n\\n### Data Sources ‚Üí Features ‚Üí Models\\n```\\nData Fetching...........................       ‚úÖ OK\\n  ‚Ü≥ VIX: 3769 observations\\n  ‚Ü≥ SPX: 3769 observations\\nFeature Engineering.....................       ‚úÖ OK\\n  ‚Ü≥ Generated 696 features\\n  ‚Ü≥ Time period: 3769 days\\nModel Training..........................       ‚úÖ OK\\n  ‚Ü≥ 15/15 detectors trained\\n  ‚Ü≥ Ensemble scores computed: 3769\\n```\\n\\n### Feature Generation Summary\\n- **Raw Market Data Points**: 7538\\n- **Engineered Features**: 696\\n- **Final Feature Set**: 696\\n- **Data Reduction Ratio**: 0.1x\\n\\n## 4. üìÖ Data Freshness & Staleness\\n\\n### Last Update Times\\n| Data Source | Last Update | Age (days) | Status |\\n|-------------|-------------|------------|--------|\\n| Main Features | 2025-11-04 | 3.9 | ‚ùå |\\n\\n### ‚ö†Ô∏è Stale Features (>5% missing in recent data)\\n- **SKEW**: 100.0% missing\\n- **SKEW_change_21d**: 100.0% missing\\n- **SKEW_zscore_63d**: 100.0% missing\\n- **PCCI**: 100.0% missing\\n- **PCCI_change_21d**: 100.0% missing\\n- **PCCI_zscore_63d**: 100.0% missing\\n- **PCCE**: 100.0% missing\\n- **PCCE_change_21d**: 100.0% missing\\n- **PCCE_zscore_63d**: 100.0% missing\\n- **PCC**: 100.0% missing\\n\\n## 5. üéØ Current Anomaly Detection Breakdown\\n\\n### Ensemble Score: 38.1%\\n\\n### Detector Contributions\\n| Detector | Score | Weight | Weighted Score | Agreement |\\n|----------|-------|--------|----------------|-----------|\\n| spx_price_action | 81.1% | 1.00 | 81.1% | üî¥ |\\n| tail_risk_complex | 79.9% | 1.00 | 79.9% | üî¥ |\\n| spx_volatility_regime | 59.1% | 1.00 | 59.1% | üî¥ |\\n| vix_momentum | 55.8% | 1.00 | 55.8% | üü¢ |\\n| vix_regime_structure | 52.0% | 1.00 | 52.0% | üü¢ |\\n| percentile_extremes | 43.4% | 1.00 | 43.4% | üü¢ |\\n| cross_asset_divergence | 38.4% | 1.00 | 38.4% | üü¢ |\\n| vix_mean_reversion | 37.9% | 1.00 | 37.9% | üü¢ |\\n| vix_spx_relationship | 31.3% | 1.00 | 31.3% | üü¢ |\\n| macro_regime_shifts | 13.4% | 1.00 | 13.4% | üî¥ |\\n| momentum_acceleration | 8.2% | 1.00 | 8.2% | üî¥ |\\n| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | üî¥ |\\n| futures_term_structure | 5.4% | 1.00 | 5.4% | üî¥ |\\n| cboe_options_flow | 1.5% | 1.00 | 1.5% | üî¥ |\\n\\n### Top Features Driving Current Anomaly\\n| Feature | Importance | Current Value | Z-Score |\\n|---------|-----------|---------------|---------|\\n| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\\n| spx_lag1 | 0.088 | 6851.97 | 2.70 |\\n| spx_ret_5d | 0.082 | -1.73 | -0.89 |\\n| spx_lag5 | 0.082 | 6890.89 | 2.74 |\\n| spx_ret_13d | 0.075 | 2.15 | 0.43 |\\n| spx_ret_63d | 0.070 | 6.72 | 0.54 |\\n| rsi_14 | 0.067 | 59.06 | 0.14 |\\n| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\\n| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\\n| bb_width_20d | 0.058 | 5.64 | -0.13 |\\n\\n## 6. üîó Feature Correlation & Redundancy Analysis\\n\\n### High Correlation Pairs (>95%)\\n| Feature 1 | Feature 2 | Correlation |\\n|-----------|-----------|-------------|\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\\n\\n**Recommendation**: Consider removing 17552 redundant features to improve performance.\\n\\n## 7. ‚ö° Performance Profiling\\n\\n### Execution Time Breakdown\\n| Operation | Time (ms) | % of Total |\\n|-----------|-----------|------------|\\n| batch_10_detections | 168.6 | 89.7% |\\n| single_detection | 19.3 | 10.3% |\\n\\n## 8. üîç Common Failure Modes & Solutions\\n\\n‚úÖ No common failure modes detected.\\n\\n## 9. üí° What-If Scenario Analysis\\n\\n### VIX Spike to 40\\n**Scenario**: If VIX suddenly spikes to 40 (crisis level)\\n**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\\n**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\\n\\n### SKEW >150\\n**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\\n**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\\n**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\\n\\n### All CBOE Data Missing\\n**Scenario**: If CBOE features become unavailable\\n**Expected Behavior**: System continues to function with reduced capability\\n**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\\n\\n## 10. üìä Data Quality Heatmap\\n\\n### Feature Quality by Category\\n| Category | Total Features | Complete | Sparse | Missing | Quality Score |\\n|----------|---------------|----------|--------|---------|---------------|\\n| VIX | 78 | 73 | 0 | 5 | 93.6% |\\n| SPX | 47 | 44 | 0 | 3 | 93.6% |\\n| CBOE | 232 | 24 | 33 | 175 | 17.5% |\\n| Futures | 45 | 35 | 10 | 0 | 88.9% |\\n| Macro | 14 | 11 | 1 | 2 | 82.1% |\\n| Meta | 280 | 84 | 122 | 74 | 51.8% |\\n\\n## 11. üöÄ System Optimization Recommendations\\n\\n### üü¢ Optimization Opportunities\\n- Remove 17552 highly correlated features to reduce redundancy\\n- Investigate 197 stale features with high recent missing data\\n- Consider adding feature selection to reduce dimensionality\\n- Implement caching for expensive feature calculations\\n- Add monitoring alerts for data freshness\\n\\n## 12. üìñ Quick Reference: Troubleshooting Guide\\n\\n\\n### Common Issues & Quick Fixes\\n\\n**Issue**: System says \"data too old\"\\n- **Check**: `system.orchestrator.features.index[-1]`\\n- **Fix**: Run `system.refresh()` or retrain with fresh data\\n\\n**Issue**: Ensemble score always near 0% or 100%\\n- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\\n- **Fix**: Retrain system to recalculate thresholds\\n\\n**Issue**: Many detectors show 0% coverage\\n- **Check**: CBOE files in `./CBOE_Data_Archive/`\\n- **Fix**: Download CBOE historical data or disable CBOE features in config\\n\\n**Issue**: \"Core data fetch failed\" error\\n- **Check**: Internet connection, yfinance API status\\n- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\\n\\n**Issue**: High memory usage\\n- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\\n- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\\n\\n**Issue**: Slow detection speed (>1 second)\\n- **Check**: Number of features and detectors active\\n- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\\n\\n**Issue**: NaN/Inf values in features\\n- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\\n- **Fix**: Review feature_engine.py for division by zero or missing data handling\\n\\n\\n---\\n*Report generated in 2.34 seconds*'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enhanced_technical_introspector import TechnicalIntrospector\n",
    "\n",
    "introspector = TechnicalIntrospector(system)\n",
    "introspector.generate_report(quick_mode=False)\n",
    "\n",
    "# # Or specific diagnostics:\n",
    "# introspector.diagnose_current_state()\n",
    "# introspector.profile_performance()\n",
    "# introspector.check_data_freshness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89090432-5699-494a-9c40-5e94c01cd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUGGING BACKFILL ISSUES\n",
      "================================================================================\n",
      "\n",
      "Found 5 predictions to backfill\n",
      "\n",
      "Prediction details:\n",
      "                          prediction_id forecast_date  horizon  current_vix\n",
      "0  4182fda2-b6b2-4431-8c60-ace1d6c90543    2025-11-10        5        18.01\n",
      "1  30649c8c-0f0f-452d-81a3-a07e3282a1b4    2025-11-10        5        18.01\n",
      "2  ef51c1a5-1edb-4b8a-a781-52bfb35c4f41    2025-11-10        5        18.01\n",
      "3  529dc6d0-7197-4bd1-88eb-feea6d1cffaa    2024-01-07        5        13.20\n",
      "4  3eb0818d-10ae-45da-a316-a91dc2a67a77    2024-01-08        5        14.04\n",
      "\n",
      "================================================================================\n",
      "FETCHING VIX DATA\n",
      "================================================================================\n",
      "\n",
      "Downloaded VIX data:\n",
      "  Type: <class 'pandas.core.frame.DataFrame'>\n",
      "  Shape: (22, 5)\n",
      "  Columns: [('Close', '^VIX'), ('High', '^VIX'), ('Low', '^VIX'), ('Open', '^VIX'), ('Volume', '^VIX')]\n",
      "\n",
      "Extracted VIX series:\n",
      "  Type: <class 'pandas.core.series.Series'>\n",
      "  Length: 22\n",
      "  Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "  Sample values:\n",
      "Date\n",
      "2025-11-04    19.00\n",
      "2025-11-05    18.01\n",
      "2025-11-06    19.50\n",
      "2025-11-07    19.08\n",
      "2025-11-10    17.77\n",
      "Name: ^VIX, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "TESTING VIX LOOKUPS\n",
      "================================================================================\n",
      "\n",
      "Prediction 1:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 2:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 3:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 4:\n",
      "  Forecast date: 2024-01-07\n",
      "  Target date: 2024-01-12\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'float'>\n",
      "     Result value: nan\n",
      "     ‚úÖ Converted to float: nan\n",
      "\n",
      "Prediction 5:\n",
      "  Forecast date: 2024-01-08\n",
      "  Target date: 2024-01-13\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'float'>\n",
      "     Result value: nan\n",
      "     ‚úÖ Converted to float: nan\n",
      "\n",
      "================================================================================\n",
      "DIAGNOSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "If you see '‚ùå Multiple values' or conversion errors above,\n",
      "that's the source of the 'ambiguous Series' error.\n",
      "\n",
      "The fix needs to handle the exact data structure returned by yfinance.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to diagnose backfill issues\n",
    "Run this to see exactly what's happening with VIX data\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "# Database path\n",
    "db_path = Path(\"data_cache/predictions.db\")\n",
    "\n",
    "# Connect and get predictions needing backfill\n",
    "conn = sqlite3.connect(db_path)\n",
    "query = \"\"\"\n",
    "SELECT prediction_id, forecast_date, horizon, current_vix\n",
    "FROM forecasts\n",
    "WHERE actual_vix_change IS NULL\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "predictions = pd.read_sql_query(query, conn, parse_dates=['forecast_date'])\n",
    "conn.close()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DEBUGGING BACKFILL ISSUES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFound {len(predictions)} predictions to backfill\")\n",
    "print(\"\\nPrediction details:\")\n",
    "print(predictions)\n",
    "\n",
    "# Fetch VIX data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FETCHING VIX DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "vix_df = yf.download(\"^VIX\", progress=False)\n",
    "print(f\"\\nDownloaded VIX data:\")\n",
    "print(f\"  Type: {type(vix_df)}\")\n",
    "print(f\"  Shape: {vix_df.shape if hasattr(vix_df, 'shape') else 'N/A'}\")\n",
    "print(f\"  Columns: {vix_df.columns.tolist() if hasattr(vix_df, 'columns') else 'N/A'}\")\n",
    "\n",
    "# Extract Close column\n",
    "if isinstance(vix_df, pd.DataFrame):\n",
    "    if 'Close' in vix_df.columns:\n",
    "        vix_series = vix_df['Close']\n",
    "    else:\n",
    "        vix_series = vix_df.iloc[:, 0]  # First column\n",
    "else:\n",
    "    vix_series = vix_df\n",
    "\n",
    "# Ensure Series\n",
    "if isinstance(vix_series, pd.DataFrame):\n",
    "    vix_series = vix_series.squeeze()\n",
    "\n",
    "print(f\"\\nExtracted VIX series:\")\n",
    "print(f\"  Type: {type(vix_series)}\")\n",
    "print(f\"  Length: {len(vix_series)}\")\n",
    "print(f\"  Index type: {type(vix_series.index)}\")\n",
    "print(f\"  Sample values:\")\n",
    "print(vix_series.tail())\n",
    "\n",
    "# Test lookup for each prediction\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TESTING VIX LOOKUPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, pred in predictions.iterrows():\n",
    "    forecast_date = pred['forecast_date']\n",
    "    horizon = pred['horizon']\n",
    "    target_date = forecast_date + pd.Timedelta(days=horizon)\n",
    "    \n",
    "    print(f\"\\nPrediction {idx + 1}:\")\n",
    "    print(f\"  Forecast date: {forecast_date.date()}\")\n",
    "    print(f\"  Target date: {target_date.date()}\")\n",
    "    print(f\"  Horizon: {horizon} days\")\n",
    "    \n",
    "    # Try exact lookup\n",
    "    if target_date in vix_series.index:\n",
    "        result = vix_series.loc[target_date]\n",
    "        print(f\"  ‚úÖ Exact match found\")\n",
    "        print(f\"     Result type: {type(result)}\")\n",
    "        print(f\"     Result value: {result}\")\n",
    "        \n",
    "        # Try to convert to float\n",
    "        try:\n",
    "            if isinstance(result, pd.Series):\n",
    "                if len(result) == 1:\n",
    "                    value = float(result.iloc[0])\n",
    "                    print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "                else:\n",
    "                    print(f\"     ‚ùå Multiple values: {len(result)}\")\n",
    "            else:\n",
    "                value = float(result)\n",
    "                print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Conversion failed: {e}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Exact match not found, trying asof...\")\n",
    "        result = vix_series.asof(target_date)\n",
    "        print(f\"     Result type: {type(result)}\")\n",
    "        print(f\"     Result value: {result}\")\n",
    "        \n",
    "        # Try to convert\n",
    "        try:\n",
    "            if isinstance(result, pd.Series):\n",
    "                if len(result) == 1:\n",
    "                    value = float(result.iloc[0])\n",
    "                    print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "                else:\n",
    "                    print(f\"     ‚ùå Multiple values: {len(result)}\")\n",
    "            else:\n",
    "                value = float(result)\n",
    "                print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Conversion failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DIAGNOSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nIf you see '‚ùå Multiple values' or conversion errors above,\")\n",
    "print(\"that's the source of the 'ambiguous Series' error.\")\n",
    "print(\"\\nThe fix needs to handle the exact data structure returned by yfinance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ffdb7ac-ebf4-469f-9afc-661da797cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           prediction_id                   timestamp  \\\n",
      "0   4182fda2-b6b2-4431-8c60-ace1d6c90543  2025-11-10T12:26:03.836832   \n",
      "1   0de2fbea-17a4-4d09-a139-b103c25a17cb  2025-11-10T13:52:39.450119   \n",
      "2   3981008d-714b-4639-9caf-226e07ecc3b4  2025-11-10T13:52:33.630141   \n",
      "3   16eec5af-8bc3-4927-b9a1-f008ba10113a  2025-11-10T21:27:03.018547   \n",
      "4   194a4504-844b-4155-9aeb-00b05fe15fbc  2025-11-10T21:26:56.875460   \n",
      "..                                   ...                         ...   \n",
      "70  087515af-12fb-439d-9c00-6849dd62f4f2  2025-11-10T13:29:34.781666   \n",
      "71  7c9e58cb-48fe-4898-acd9-cd81397a5751  2025-11-10T13:28:52.294450   \n",
      "72  f852b8fd-6527-40ad-8dff-d61ad80d28d2  2025-11-10T13:28:46.147887   \n",
      "73  3eb0818d-10ae-45da-a316-a91dc2a67a77  2025-11-10T13:28:39.749458   \n",
      "74  529dc6d0-7197-4bd1-88eb-feea6d1cffaa  2025-11-10T13:28:33.003388   \n",
      "\n",
      "   forecast_date  horizon       calendar_cohort  cohort_weight  \\\n",
      "0     2025-11-10        5             mid_cycle            1.0   \n",
      "1     2025-11-09        5             mid_cycle            1.0   \n",
      "2     2025-11-08        5             mid_cycle            1.0   \n",
      "3     2025-11-05        5             mid_cycle            1.0   \n",
      "4     2025-11-04        5             mid_cycle            1.0   \n",
      "..           ...      ...                   ...            ...   \n",
      "70    2024-01-22        5  monthly_opex_minus_1            1.5   \n",
      "71    2024-01-10        5             mid_cycle            1.0   \n",
      "72    2024-01-09        5             mid_cycle            1.0   \n",
      "73    2024-01-08        5             mid_cycle            1.0   \n",
      "74    2024-01-07        5             mid_cycle            1.0   \n",
      "\n",
      "    point_estimate        q10        q25        q50  ...  num_features_used  \\\n",
      "0         0.012066 -15.110287 -10.199914  -2.373142  ...                232   \n",
      "1        -5.265536 -16.217798 -13.196301  -3.015103  ...                232   \n",
      "2        -0.304104 -13.725952  -7.642770  -0.337722  ...                232   \n",
      "3        -1.287468 -12.812272  -9.657278  -1.320925  ...                232   \n",
      "4         6.006715  -9.538655  -5.289082   2.289049  ...                232   \n",
      "..             ...        ...        ...        ...  ...                ...   \n",
      "70      -11.108871 -11.687101 -11.165680 -11.154345  ...                232   \n",
      "71       -4.900398  -7.275025  -4.864093  -4.864093  ...                232   \n",
      "72      -11.903585 -11.941021 -11.941021 -11.941021  ...                232   \n",
      "73       -9.987429 -11.183056  -9.614321  -9.595574  ...                232   \n",
      "74       -3.505539  -6.753812  -3.332309  -3.317016  ...                232   \n",
      "\n",
      "    missing_features  current_vix  actual_vix_change  actual_regime  \\\n",
      "0               None    18.010000                NaN           None   \n",
      "1               None    19.000000                NaN           None   \n",
      "2               None    17.170000                NaN           None   \n",
      "3               None    17.440001           0.917430         Normal   \n",
      "4               None    16.910000          12.832644         Normal   \n",
      "..               ...          ...                ...            ...   \n",
      "70              None    14.790000          -8.045974            Low   \n",
      "71              None    13.350000          10.786513       Elevated   \n",
      "72              None    14.130000          -2.052371         Normal   \n",
      "73              None    14.040000          -1.424500         Normal   \n",
      "74              None    13.200000          -3.787879         Normal   \n",
      "\n",
      "    point_error                                  quantile_coverage  \\\n",
      "0           NaN                                               None   \n",
      "1           NaN                                               None   \n",
      "2           NaN                                               None   \n",
      "3      2.204899  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "4      6.825929  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "..          ...                                                ...   \n",
      "70     3.062897                                               None   \n",
      "71    15.686911                                               None   \n",
      "72     9.851215                                               None   \n",
      "73     8.562929                                               None   \n",
      "74     0.282339                                               None   \n",
      "\n",
      "                                        features_used model_version  \\\n",
      "0   {\"vix\": 18.010000228881836, \"spx_lag1\": 6771.5...   git-864b4aa   \n",
      "1   {\"vix\": 19.0, \"spx_lag1\": 6851.97021484375, \"v...   git-864b4aa   \n",
      "2   {\"vix\": 17.170000076293945, \"spx_lag1\": 6840.2...   git-864b4aa   \n",
      "3   {\"vix\": 17.440000534057617, \"spx_lag1\": 6822.3...   git-864b4aa   \n",
      "4   {\"vix\": 16.90999984741211, \"spx_lag1\": 6890.58...   git-864b4aa   \n",
      "..                                                ...           ...   \n",
      "70  {\"vix\": 14.789999961853027, \"spx_lag1\": 4765.9...   git-864b4aa   \n",
      "71  {\"vix\": 13.350000381469727, \"spx_lag1\": 4688.6...   git-864b4aa   \n",
      "72  {\"vix\": 14.130000114440918, \"spx_lag1\": 4704.8...   git-864b4aa   \n",
      "73  {\"vix\": 14.039999961853027, \"spx_lag1\": 4742.8...   git-864b4aa   \n",
      "74  {\"vix\": 13.199999809265137, \"spx_lag1\": 4769.8...   git-864b4aa   \n",
      "\n",
      "                    created_at  \n",
      "0   2025-11-10T12:26:03.862453  \n",
      "1   2025-11-10T13:52:39.469317  \n",
      "2   2025-11-10T13:52:33.712613  \n",
      "3   2025-11-10T21:27:03.037189  \n",
      "4   2025-11-10T21:26:56.892967  \n",
      "..                         ...  \n",
      "70  2025-11-10T13:29:34.815911  \n",
      "71  2025-11-10T13:28:52.314665  \n",
      "72  2025-11-10T13:28:46.164894  \n",
      "73  2025-11-10T13:28:39.775260  \n",
      "74  2025-11-10T13:28:33.037991  \n",
      "\n",
      "[75 rows x 29 columns]\n",
      "\n",
      "Today: 2025-11-11\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'has_actual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'has_actual'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mToday: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions with actuals: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhas_actual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'has_actual'"
     ]
    }
   ],
   "source": [
    "# Quick diagnostic script\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data_cache/predictions.db')\n",
    "\n",
    "# Check prediction dates\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        forecast_date,\n",
    "        horizon,\n",
    "        actual_vix_change IS NOT NULL as has_actual,\n",
    "        date(forecast_date, '+' || horizon || ' days') as target_date\n",
    "    FROM forecasts\n",
    "    ORDER BY forecast_date DESC\n",
    "    LIMIT 100\n",
    "\"\"\", conn, parse_dates=['forecast_date', 'target_date'])\n",
    "\n",
    "print(df)\n",
    "print(f\"\\nToday: {pd.Timestamp.now().date()}\")\n",
    "print(f\"Predictions with actuals: {df['has_actual'].sum()}/{len(df)}\")\n",
    "    FROM forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd39e3d5-d486-4cbf-b415-84c81ed6e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DUPLICATE CLEANUP\n",
      "================================================================================\n",
      "‚úÖ No duplicates found\n",
      "\n",
      "================================================================================\n",
      "DATABASE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total predictions: 75\n",
      "  ‚úÖ With actuals: 72\n",
      "  ‚è≥ Pending actuals: 3\n",
      "\n",
      "Date range: 2024-01-07T00:00:00 to 2025-11-10T00:00:00\n",
      "Remaining duplicates: 0\n",
      "  ‚úÖ No duplicates\n",
      "\n",
      "Predictions by cohort:\n",
      "  mid_cycle                :   45\n",
      "  monthly_opex_minus_1     :   11\n",
      "  fomc_minus_3             :    7\n",
      "  earnings_heavy           :    6\n",
      "  monthly_opex_minus_5     :    6\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Standalone script to clean duplicate predictions and show database stats.\n",
    "Run from src/ directory: python cleanup_duplicates.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we can import from current directory\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = \"data_cache/predictions.db\"\n",
    "\n",
    "def remove_duplicates():\n",
    "    \"\"\"Remove duplicate predictions, keeping the earliest by timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DUPLICATE CLEANUP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Find duplicates\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT forecast_date, horizon, COUNT(*) as count\n",
    "        FROM forecasts\n",
    "        GROUP BY forecast_date, horizon\n",
    "        HAVING count > 1\n",
    "    \"\"\")\n",
    "    \n",
    "    duplicates = cursor.fetchall()\n",
    "    \n",
    "    if len(duplicates) == 0:\n",
    "        print(\"‚úÖ No duplicates found\")\n",
    "        conn.close()\n",
    "        return 0\n",
    "    \n",
    "    print(f\"‚ö†Ô∏è  Found {len(duplicates)} duplicate date-horizon pairs\\n\")\n",
    "    \n",
    "    # Show sample duplicates\n",
    "    print(\"Sample duplicates:\")\n",
    "    for i, (forecast_date, horizon, count) in enumerate(duplicates[:5], 1):\n",
    "        print(f\"  {i}. {forecast_date} (horizon={horizon}): {count} copies\")\n",
    "    \n",
    "    if len(duplicates) > 5:\n",
    "        print(f\"  ... and {len(duplicates) - 5} more\")\n",
    "    \n",
    "    # Remove duplicates (keep earliest)\n",
    "    total_removed = 0\n",
    "    for forecast_date, horizon, count in duplicates:\n",
    "        cursor = conn.execute(\"\"\"\n",
    "            DELETE FROM forecasts\n",
    "            WHERE forecast_date = ? AND horizon = ?\n",
    "            AND prediction_id NOT IN (\n",
    "                SELECT prediction_id FROM forecasts\n",
    "                WHERE forecast_date = ? AND horizon = ?\n",
    "                ORDER BY timestamp ASC\n",
    "                LIMIT 1\n",
    "            )\n",
    "        \"\"\", (forecast_date, horizon, forecast_date, horizon))\n",
    "        \n",
    "        removed = cursor.rowcount\n",
    "        total_removed += removed\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Removed {total_removed} duplicate predictions\")\n",
    "    return total_removed\n",
    "\n",
    "\n",
    "def show_stats():\n",
    "    \"\"\"Show database statistics.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATABASE STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Total predictions\n",
    "    cursor = conn.execute(\"SELECT COUNT(*) FROM forecasts\")\n",
    "    total = cursor.fetchone()[0]\n",
    "    \n",
    "    # With actuals\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM forecasts\n",
    "        WHERE actual_vix_change IS NOT NULL\n",
    "    \"\"\")\n",
    "    with_actuals = cursor.fetchone()[0]\n",
    "    \n",
    "    # Date range\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT MIN(forecast_date) as earliest, MAX(forecast_date) as latest\n",
    "        FROM forecasts\n",
    "    \"\"\")\n",
    "    earliest, latest = cursor.fetchone()\n",
    "    \n",
    "    # Remaining duplicates (should be 0 after cleanup)\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM (\n",
    "            SELECT forecast_date, horizon, COUNT(*) as count\n",
    "            FROM forecasts\n",
    "            GROUP BY forecast_date, horizon\n",
    "            HAVING count > 1\n",
    "        )\n",
    "    \"\"\")\n",
    "    remaining_dupes = cursor.fetchone()[0]\n",
    "    \n",
    "    print(f\"\\nTotal predictions: {total}\")\n",
    "    print(f\"  ‚úÖ With actuals: {with_actuals}\")\n",
    "    print(f\"  ‚è≥ Pending actuals: {total - with_actuals}\")\n",
    "    print(f\"\\nDate range: {earliest} to {latest}\")\n",
    "    print(f\"Remaining duplicates: {remaining_dupes}\")\n",
    "    \n",
    "    if remaining_dupes > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: {remaining_dupes} duplicate pairs still exist!\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ No duplicates\")\n",
    "    \n",
    "    # Cohort breakdown\n",
    "    print(f\"\\nPredictions by cohort:\")\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT calendar_cohort, COUNT(*) as count\n",
    "        FROM forecasts\n",
    "        GROUP BY calendar_cohort\n",
    "        ORDER BY count DESC\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"  {row['calendar_cohort']:25s}: {row['count']:4d}\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run cleanup and show stats.\"\"\"\n",
    "    if not Path(DB_PATH).exists():\n",
    "        print(f\"‚ùå Database not found: {DB_PATH}\")\n",
    "        print(f\"   Run batch forecasting first:\")\n",
    "        print(f\"   python integrated_system_production.py --mode batch \\\\\")\n",
    "        print(f\"     --start-date 2025-08-01 --end-date 2025-11-10\")\n",
    "        return\n",
    "    \n",
    "    # Remove duplicates\n",
    "    removed = remove_duplicates()\n",
    "    \n",
    "    # Show final stats\n",
    "    show_stats()\n",
    "    \n",
    "    if removed > 0:\n",
    "        print(\"‚úÖ Database cleaned successfully\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55ecaa34-6a95-4396-952f-2bca720a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          forecast_date  confidence_score  current_vix  \\\n",
      "0   2025-11-05T00:00:00          0.939116    17.440001   \n",
      "1   2025-11-04T00:00:00          0.938339    16.910000   \n",
      "2   2025-11-03T00:00:00          0.943604    16.920000   \n",
      "3   2025-11-02T00:00:00          0.849609    16.420000   \n",
      "4   2025-11-01T00:00:00          0.849609    15.790000   \n",
      "5   2025-10-29T00:00:00          0.849609    16.370001   \n",
      "6   2025-10-28T00:00:00          0.849609    17.299999   \n",
      "7   2025-10-27T00:00:00          0.801657    18.600000   \n",
      "8   2025-10-26T00:00:00          0.801657    17.870001   \n",
      "9   2025-10-25T00:00:00          0.798351    18.230000   \n",
      "10  2025-10-22T00:00:00          0.471167    20.780001   \n",
      "11  2025-10-21T00:00:00          0.471167    25.309999   \n",
      "12  2025-10-20T00:00:00          0.471167    20.639999   \n",
      "13  2025-10-19T00:00:00          0.754279    20.809999   \n",
      "14  2025-10-18T00:00:00          0.751119    19.030001   \n",
      "15  2025-10-15T00:00:00          0.754279    21.660000   \n",
      "16  2025-10-14T00:00:00          0.849609    16.430000   \n",
      "17  2025-10-13T00:00:00          0.849609    16.299999   \n",
      "18  2025-10-12T00:00:00          0.953841    17.240000   \n",
      "19  2025-10-11T00:00:00          0.955552    16.370001   \n",
      "20  2025-10-08T00:00:00          0.955552    16.650000   \n",
      "21  2025-10-07T00:00:00          0.955552    16.629999   \n",
      "22  2025-10-06T00:00:00          0.955552    16.290001   \n",
      "23  2025-10-05T00:00:00          0.954687    16.280001   \n",
      "24  2025-10-04T00:00:00          0.953841    16.120001   \n",
      "25  2025-10-01T00:00:00          0.953841    15.290000   \n",
      "26  2025-09-30T00:00:00          0.953841    16.740000   \n",
      "27  2025-09-29T00:00:00          0.953841    16.180000   \n",
      "28  2025-09-28T00:00:00          0.953841    16.639999   \n",
      "29  2025-09-27T00:00:00          0.953841    16.100000   \n",
      "30  2025-09-24T00:00:00          0.471167    15.450000   \n",
      "31  2025-09-23T00:00:00          0.471167    15.700000   \n",
      "32  2025-09-22T00:00:00          0.572305    15.720000   \n",
      "33  2025-09-21T00:00:00          0.659976    16.360001   \n",
      "34  2025-09-20T00:00:00          0.659976    15.690000   \n",
      "35  2025-09-17T00:00:00          0.659976    14.760000   \n",
      "36  2025-09-16T00:00:00          0.953841    14.710000   \n",
      "37  2025-09-15T00:00:00          0.953841    15.350000   \n",
      "38  2025-09-14T00:00:00          0.953841    15.040000   \n",
      "39  2025-09-13T00:00:00          0.953841    15.110000   \n",
      "40  2025-09-10T00:00:00          0.953841    15.180000   \n",
      "41  2025-09-09T00:00:00          0.953841    15.300000   \n",
      "42  2025-09-08T00:00:00          0.953841    16.350000   \n",
      "43  2025-09-07T00:00:00          0.953841    17.170000   \n",
      "44  2025-09-03T00:00:00          0.945474    15.360000   \n",
      "45  2025-09-02T00:00:00          0.945474    14.430000   \n",
      "46  2025-09-01T00:00:00          0.945474    14.850000   \n",
      "47  2025-08-31T00:00:00          0.945474    14.620000   \n",
      "48  2025-08-30T00:00:00          0.945474    14.790000   \n",
      "49  2025-08-27T00:00:00          0.567284    14.220000   \n",
      "\n",
      "                                    quantile_coverage  \\\n",
      "0   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "1   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "2   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "3   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "4   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "5   {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "6   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "7   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "8   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "9   {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "10  {\"q10\": 1, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "11  {\"q10\": 1, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "12  {\"q10\": 1, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "13  {\"q10\": 1, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "14  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "15  {\"q10\": 1, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "16  {\"q10\": 0, \"q25\": 0, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "17  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "18  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "19  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "20  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "21  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "22  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "23  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "24  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "25  {\"q10\": 0, \"q25\": 0, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "26  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "27  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "28  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "29  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "30  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "31  {\"q10\": 0, \"q25\": 0, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "32  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "33  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "34  {\"q10\": 0, \"q25\": 0, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "35  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "36  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "37  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "38  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "39  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "40  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "41  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "42  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "43  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 1, \"q90\"...   \n",
      "44  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "45  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "46  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "47  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "48  {\"q10\": 0, \"q25\": 1, \"q50\": 1, \"q75\": 1, \"q90\"...   \n",
      "49  {\"q10\": 0, \"q25\": 0, \"q50\": 0, \"q75\": 0, \"q90\"...   \n",
      "\n",
      "                    created_at  \n",
      "0   2025-11-10T21:27:03.037189  \n",
      "1   2025-11-10T21:26:56.892967  \n",
      "2   2025-11-10T21:26:50.502377  \n",
      "3   2025-11-10T21:26:43.164803  \n",
      "4   2025-11-10T21:26:35.293618  \n",
      "5   2025-11-10T21:26:27.423912  \n",
      "6   2025-11-10T21:26:21.260576  \n",
      "7   2025-11-10T21:26:14.664736  \n",
      "8   2025-11-10T21:26:07.293112  \n",
      "9   2025-11-10T14:37:27.607525  \n",
      "10  2025-11-10T14:37:20.995198  \n",
      "11  2025-11-10T14:37:15.134865  \n",
      "12  2025-11-10T14:37:09.276796  \n",
      "13  2025-11-10T14:37:03.242167  \n",
      "14  2025-11-10T14:36:57.443997  \n",
      "15  2025-11-10T14:36:51.262445  \n",
      "16  2025-11-10T14:36:45.346444  \n",
      "17  2025-11-10T14:36:39.283838  \n",
      "18  2025-11-10T14:36:32.834354  \n",
      "19  2025-11-10T14:36:26.351028  \n",
      "20  2025-11-10T14:36:19.828849  \n",
      "21  2025-11-10T14:36:14.114450  \n",
      "22  2025-11-10T14:36:08.400035  \n",
      "23  2025-11-10T19:40:15.800267  \n",
      "24  2025-11-11T10:07:21.187021  \n",
      "25  2025-11-11T10:07:15.355782  \n",
      "26  2025-11-11T10:07:08.972417  \n",
      "27  2025-11-11T10:07:02.999502  \n",
      "28  2025-11-11T10:06:57.003686  \n",
      "29  2025-11-11T10:06:51.054118  \n",
      "30  2025-11-11T10:06:44.892394  \n",
      "31  2025-11-11T10:06:38.898848  \n",
      "32  2025-11-11T10:06:32.934927  \n",
      "33  2025-11-11T10:06:26.634735  \n",
      "34  2025-11-11T10:06:20.643952  \n",
      "35  2025-11-11T10:06:14.750107  \n",
      "36  2025-11-11T10:06:08.630804  \n",
      "37  2025-11-11T10:06:02.679389  \n",
      "38  2025-11-11T10:05:56.822450  \n",
      "39  2025-11-11T10:05:51.043231  \n",
      "40  2025-11-11T10:05:45.162914  \n",
      "41  2025-11-11T10:05:39.038202  \n",
      "42  2025-11-11T10:05:33.080909  \n",
      "43  2025-11-11T10:05:26.970707  \n",
      "44  2025-11-11T10:14:49.729571  \n",
      "45  2025-11-11T10:14:42.930951  \n",
      "46  2025-11-11T10:14:36.768833  \n",
      "47  2025-11-11T10:14:30.679025  \n",
      "48  2025-11-11T10:14:24.635740  \n",
      "49  2025-11-11T10:14:18.516693  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"data_cache/predictions.db\")\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        forecast_date, \n",
    "        confidence_score, \n",
    "        current_vix, \n",
    "        quantile_coverage,\n",
    "        created_at \n",
    "    FROM forecasts \n",
    "    ORDER BY forecast_date DESC\n",
    "    LIMIT 50\n",
    "\"\"\", conn)\n",
    "print(df)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b580c5b-95df-42fc-9c85-c14d00da22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deleted 0 incomplete skeleton predictions\n"
     ]
    }
   ],
   "source": [
    "# Quick database cleanup script\n",
    "import sqlite3\n",
    "\n",
    "db_path = \"data_cache/predictions.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Delete predictions with missing actuals from your skeleton run\n",
    "cursor.execute(\"\"\"\n",
    "    DELETE FROM forecasts \n",
    "    WHERE forecast_date >= '2024-01-01' \n",
    "    AND quantile_coverage IS NULL\n",
    "\"\"\")\n",
    "\n",
    "deleted = cursor.rowcount\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"‚úÖ Deleted {deleted} incomplete skeleton predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cd7c3-7990-4da5-aca2-09d5386fd92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ce1c471-c980-4074-98bc-df9c7e3ce1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Technical diagnostic report saved: ./docs/TECHNICAL_DIAGNOSTIC.md\n",
      "   Issues found: 0\n",
      "   Warnings: 0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# üîß Technical System Diagnostic Report\n",
       "\n",
       "*Generated: 2025-11-07 22:06:43*\n",
       "*Quick Mode: OFF*\n",
       "\n",
       "---\n",
       "\n",
       "## 1. üè• System Health Check\n",
       "\n",
       "**Overall Status**: ‚úÖ HEALTHY\n",
       "\n",
       "### Component Status\n",
       "| Component | Status | Details |\n",
       "|-----------|--------|---------|\n",
       "| data | ‚úÖ | 3769 rows |\n",
       "| model | ‚úÖ | Trained |\n",
       "| detector_coverage | ‚úÖ | 0 detectors with <70% coverage |\n",
       "| data_freshness | ‚úÖ | 3 days old |\n",
       "| data_completeness | ‚úÖ | 79.1% complete |\n",
       "\n",
       "## 2. üéõÔ∏è Model Configuration Deep Dive\n",
       "\n",
       "### Anomaly Detector Configuration\n",
       "```python\n",
       "contamination: 0.050\n",
       "n_estimators: 100\n",
       "max_samples: auto\n",
       "random_state: 42\n",
       "```\n",
       "\n",
       "### Individual Detector Parameters\n",
       "| Detector | Features Used | Coverage | Active |\n",
       "|----------|--------------|----------|--------|\n",
       "| vix_mean_reversion | 18 | 100.0% | ‚úÖ |\n",
       "| vix_momentum | 18 | 100.0% | ‚úÖ |\n",
       "| vix_regime_structure | 18 | 100.0% | ‚úÖ |\n",
       "| cboe_options_flow | 39 | 100.0% | ‚úÖ |\n",
       "| cboe_cross_dynamics | 17 | 100.0% | ‚úÖ |\n",
       "| vix_spx_relationship | 17 | 100.0% | ‚úÖ |\n",
       "| spx_price_action | 15 | 75.0% | ‚úÖ |\n",
       "| spx_volatility_regime | 20 | 90.9% | ‚úÖ |\n",
       "| cross_asset_divergence | 23 | 88.5% | ‚úÖ |\n",
       "| tail_risk_complex | 15 | 83.3% | ‚úÖ |\n",
       "| futures_term_structure | 27 | 100.0% | ‚úÖ |\n",
       "| macro_regime_shifts | 19 | 100.0% | ‚úÖ |\n",
       "| momentum_acceleration | 20 | 100.0% | ‚úÖ |\n",
       "| percentile_extremes | 19 | 100.0% | ‚úÖ |\n",
       "| random_4 | 0 | 0.0% | ‚úÖ |\n",
       "\n",
       "## 3. üîÑ Data Pipeline Flow Trace\n",
       "\n",
       "### Data Sources ‚Üí Features ‚Üí Models\n",
       "```\n",
       "Data Fetching...........................       ‚úÖ OK\n",
       "  ‚Ü≥ VIX: 3769 observations\n",
       "  ‚Ü≥ SPX: 3769 observations\n",
       "Feature Engineering.....................       ‚úÖ OK\n",
       "  ‚Ü≥ Generated 696 features\n",
       "  ‚Ü≥ Time period: 3769 days\n",
       "Model Training..........................       ‚úÖ OK\n",
       "  ‚Ü≥ 15/15 detectors trained\n",
       "  ‚Ü≥ Ensemble scores computed: 3769\n",
       "```\n",
       "\n",
       "### Feature Generation Summary\n",
       "- **Raw Market Data Points**: 7538\n",
       "- **Engineered Features**: 696\n",
       "- **Final Feature Set**: 696\n",
       "- **Data Reduction Ratio**: 0.1x\n",
       "\n",
       "## 4. üìÖ Data Freshness & Staleness\n",
       "\n",
       "### Last Update Times\n",
       "| Data Source | Last Update | Age (days) | Status |\n",
       "|-------------|-------------|------------|--------|\n",
       "| Main Features | 2025-11-04 | 3.9 | ‚ùå |\n",
       "\n",
       "### ‚ö†Ô∏è Stale Features (>5% missing in recent data)\n",
       "- **SKEW**: 100.0% missing\n",
       "- **SKEW_change_21d**: 100.0% missing\n",
       "- **SKEW_zscore_63d**: 100.0% missing\n",
       "- **PCCI**: 100.0% missing\n",
       "- **PCCI_change_21d**: 100.0% missing\n",
       "- **PCCI_zscore_63d**: 100.0% missing\n",
       "- **PCCE**: 100.0% missing\n",
       "- **PCCE_change_21d**: 100.0% missing\n",
       "- **PCCE_zscore_63d**: 100.0% missing\n",
       "- **PCC**: 100.0% missing\n",
       "\n",
       "## 5. üéØ Current Anomaly Detection Breakdown\n",
       "\n",
       "### Ensemble Score: 38.1%\n",
       "\n",
       "### Detector Contributions\n",
       "| Detector | Score | Weight | Weighted Score | Agreement |\n",
       "|----------|-------|--------|----------------|-----------|\n",
       "| spx_price_action | 81.1% | 1.00 | 81.1% | üî¥ |\n",
       "| tail_risk_complex | 79.9% | 1.00 | 79.9% | üî¥ |\n",
       "| spx_volatility_regime | 59.1% | 1.00 | 59.1% | üî¥ |\n",
       "| vix_momentum | 55.8% | 1.00 | 55.8% | üü¢ |\n",
       "| vix_regime_structure | 52.0% | 1.00 | 52.0% | üü¢ |\n",
       "| percentile_extremes | 43.4% | 1.00 | 43.4% | üü¢ |\n",
       "| cross_asset_divergence | 38.4% | 1.00 | 38.4% | üü¢ |\n",
       "| vix_mean_reversion | 37.9% | 1.00 | 37.9% | üü¢ |\n",
       "| vix_spx_relationship | 31.3% | 1.00 | 31.3% | üü¢ |\n",
       "| macro_regime_shifts | 13.4% | 1.00 | 13.4% | üî¥ |\n",
       "| momentum_acceleration | 8.2% | 1.00 | 8.2% | üî¥ |\n",
       "| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | üî¥ |\n",
       "| futures_term_structure | 5.4% | 1.00 | 5.4% | üî¥ |\n",
       "| cboe_options_flow | 1.5% | 1.00 | 1.5% | üî¥ |\n",
       "\n",
       "### Top Features Driving Current Anomaly\n",
       "| Feature | Importance | Current Value | Z-Score |\n",
       "|---------|-----------|---------------|---------|\n",
       "| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\n",
       "| spx_lag1 | 0.088 | 6851.97 | 2.70 |\n",
       "| spx_ret_5d | 0.082 | -1.73 | -0.89 |\n",
       "| spx_lag5 | 0.082 | 6890.89 | 2.74 |\n",
       "| spx_ret_13d | 0.075 | 2.15 | 0.43 |\n",
       "| spx_ret_63d | 0.070 | 6.72 | 0.54 |\n",
       "| rsi_14 | 0.067 | 59.06 | 0.14 |\n",
       "| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\n",
       "| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\n",
       "| bb_width_20d | 0.058 | 5.64 | -0.13 |\n",
       "\n",
       "## 6. üîó Feature Correlation & Redundancy Analysis\n",
       "\n",
       "### High Correlation Pairs (>95%)\n",
       "| Feature 1 | Feature 2 | Correlation |\n",
       "|-----------|-----------|-------------|\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\n",
       "| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\n",
       "\n",
       "**Recommendation**: Consider removing 17552 redundant features to improve performance.\n",
       "\n",
       "## 7. ‚ö° Performance Profiling\n",
       "\n",
       "### Execution Time Breakdown\n",
       "| Operation | Time (ms) | % of Total |\n",
       "|-----------|-----------|------------|\n",
       "| batch_10_detections | 168.6 | 89.7% |\n",
       "| single_detection | 19.3 | 10.3% |\n",
       "\n",
       "## 8. üîç Common Failure Modes & Solutions\n",
       "\n",
       "‚úÖ No common failure modes detected.\n",
       "\n",
       "## 9. üí° What-If Scenario Analysis\n",
       "\n",
       "### VIX Spike to 40\n",
       "**Scenario**: If VIX suddenly spikes to 40 (crisis level)\n",
       "**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\n",
       "**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\n",
       "\n",
       "### SKEW >150\n",
       "**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\n",
       "**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\n",
       "**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\n",
       "\n",
       "### All CBOE Data Missing\n",
       "**Scenario**: If CBOE features become unavailable\n",
       "**Expected Behavior**: System continues to function with reduced capability\n",
       "**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\n",
       "\n",
       "## 10. üìä Data Quality Heatmap\n",
       "\n",
       "### Feature Quality by Category\n",
       "| Category | Total Features | Complete | Sparse | Missing | Quality Score |\n",
       "|----------|---------------|----------|--------|---------|---------------|\n",
       "| VIX | 78 | 73 | 0 | 5 | 93.6% |\n",
       "| SPX | 47 | 44 | 0 | 3 | 93.6% |\n",
       "| CBOE | 232 | 24 | 33 | 175 | 17.5% |\n",
       "| Futures | 45 | 35 | 10 | 0 | 88.9% |\n",
       "| Macro | 14 | 11 | 1 | 2 | 82.1% |\n",
       "| Meta | 280 | 84 | 122 | 74 | 51.8% |\n",
       "\n",
       "## 11. üöÄ System Optimization Recommendations\n",
       "\n",
       "### üü¢ Optimization Opportunities\n",
       "- Remove 17552 highly correlated features to reduce redundancy\n",
       "- Investigate 197 stale features with high recent missing data\n",
       "- Consider adding feature selection to reduce dimensionality\n",
       "- Implement caching for expensive feature calculations\n",
       "- Add monitoring alerts for data freshness\n",
       "\n",
       "## 12. üìñ Quick Reference: Troubleshooting Guide\n",
       "\n",
       "\n",
       "### Common Issues & Quick Fixes\n",
       "\n",
       "**Issue**: System says \"data too old\"\n",
       "- **Check**: `system.orchestrator.features.index[-1]`\n",
       "- **Fix**: Run `system.refresh()` or retrain with fresh data\n",
       "\n",
       "**Issue**: Ensemble score always near 0% or 100%\n",
       "- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\n",
       "- **Fix**: Retrain system to recalculate thresholds\n",
       "\n",
       "**Issue**: Many detectors show 0% coverage\n",
       "- **Check**: CBOE files in `./CBOE_Data_Archive/`\n",
       "- **Fix**: Download CBOE historical data or disable CBOE features in config\n",
       "\n",
       "**Issue**: \"Core data fetch failed\" error\n",
       "- **Check**: Internet connection, yfinance API status\n",
       "- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\n",
       "\n",
       "**Issue**: High memory usage\n",
       "- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\n",
       "- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\n",
       "\n",
       "**Issue**: Slow detection speed (>1 second)\n",
       "- **Check**: Number of features and detectors active\n",
       "- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\n",
       "\n",
       "**Issue**: NaN/Inf values in features\n",
       "- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\n",
       "- **Fix**: Review feature_engine.py for division by zero or missing data handling\n",
       "\n",
       "\n",
       "---\n",
       "*Report generated in 2.34 seconds*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'# üîß Technical System Diagnostic Report\\n\\n*Generated: 2025-11-07 22:06:43*\\n*Quick Mode: OFF*\\n\\n---\\n\\n## 1. üè• System Health Check\\n\\n**Overall Status**: ‚úÖ HEALTHY\\n\\n### Component Status\\n| Component | Status | Details |\\n|-----------|--------|---------|\\n| data | ‚úÖ | 3769 rows |\\n| model | ‚úÖ | Trained |\\n| detector_coverage | ‚úÖ | 0 detectors with <70% coverage |\\n| data_freshness | ‚úÖ | 3 days old |\\n| data_completeness | ‚úÖ | 79.1% complete |\\n\\n## 2. üéõÔ∏è Model Configuration Deep Dive\\n\\n### Anomaly Detector Configuration\\n```python\\ncontamination: 0.050\\nn_estimators: 100\\nmax_samples: auto\\nrandom_state: 42\\n```\\n\\n### Individual Detector Parameters\\n| Detector | Features Used | Coverage | Active |\\n|----------|--------------|----------|--------|\\n| vix_mean_reversion | 18 | 100.0% | ‚úÖ |\\n| vix_momentum | 18 | 100.0% | ‚úÖ |\\n| vix_regime_structure | 18 | 100.0% | ‚úÖ |\\n| cboe_options_flow | 39 | 100.0% | ‚úÖ |\\n| cboe_cross_dynamics | 17 | 100.0% | ‚úÖ |\\n| vix_spx_relationship | 17 | 100.0% | ‚úÖ |\\n| spx_price_action | 15 | 75.0% | ‚úÖ |\\n| spx_volatility_regime | 20 | 90.9% | ‚úÖ |\\n| cross_asset_divergence | 23 | 88.5% | ‚úÖ |\\n| tail_risk_complex | 15 | 83.3% | ‚úÖ |\\n| futures_term_structure | 27 | 100.0% | ‚úÖ |\\n| macro_regime_shifts | 19 | 100.0% | ‚úÖ |\\n| momentum_acceleration | 20 | 100.0% | ‚úÖ |\\n| percentile_extremes | 19 | 100.0% | ‚úÖ |\\n| random_4 | 0 | 0.0% | ‚úÖ |\\n\\n## 3. üîÑ Data Pipeline Flow Trace\\n\\n### Data Sources ‚Üí Features ‚Üí Models\\n```\\nData Fetching...........................       ‚úÖ OK\\n  ‚Ü≥ VIX: 3769 observations\\n  ‚Ü≥ SPX: 3769 observations\\nFeature Engineering.....................       ‚úÖ OK\\n  ‚Ü≥ Generated 696 features\\n  ‚Ü≥ Time period: 3769 days\\nModel Training..........................       ‚úÖ OK\\n  ‚Ü≥ 15/15 detectors trained\\n  ‚Ü≥ Ensemble scores computed: 3769\\n```\\n\\n### Feature Generation Summary\\n- **Raw Market Data Points**: 7538\\n- **Engineered Features**: 696\\n- **Final Feature Set**: 696\\n- **Data Reduction Ratio**: 0.1x\\n\\n## 4. üìÖ Data Freshness & Staleness\\n\\n### Last Update Times\\n| Data Source | Last Update | Age (days) | Status |\\n|-------------|-------------|------------|--------|\\n| Main Features | 2025-11-04 | 3.9 | ‚ùå |\\n\\n### ‚ö†Ô∏è Stale Features (>5% missing in recent data)\\n- **SKEW**: 100.0% missing\\n- **SKEW_change_21d**: 100.0% missing\\n- **SKEW_zscore_63d**: 100.0% missing\\n- **PCCI**: 100.0% missing\\n- **PCCI_change_21d**: 100.0% missing\\n- **PCCI_zscore_63d**: 100.0% missing\\n- **PCCE**: 100.0% missing\\n- **PCCE_change_21d**: 100.0% missing\\n- **PCCE_zscore_63d**: 100.0% missing\\n- **PCC**: 100.0% missing\\n\\n## 5. üéØ Current Anomaly Detection Breakdown\\n\\n### Ensemble Score: 38.1%\\n\\n### Detector Contributions\\n| Detector | Score | Weight | Weighted Score | Agreement |\\n|----------|-------|--------|----------------|-----------|\\n| spx_price_action | 81.1% | 1.00 | 81.1% | üî¥ |\\n| tail_risk_complex | 79.9% | 1.00 | 79.9% | üî¥ |\\n| spx_volatility_regime | 59.1% | 1.00 | 59.1% | üî¥ |\\n| vix_momentum | 55.8% | 1.00 | 55.8% | üü¢ |\\n| vix_regime_structure | 52.0% | 1.00 | 52.0% | üü¢ |\\n| percentile_extremes | 43.4% | 1.00 | 43.4% | üü¢ |\\n| cross_asset_divergence | 38.4% | 1.00 | 38.4% | üü¢ |\\n| vix_mean_reversion | 37.9% | 1.00 | 37.9% | üü¢ |\\n| vix_spx_relationship | 31.3% | 1.00 | 31.3% | üü¢ |\\n| macro_regime_shifts | 13.4% | 1.00 | 13.4% | üî¥ |\\n| momentum_acceleration | 8.2% | 1.00 | 8.2% | üî¥ |\\n| cboe_cross_dynamics | 7.7% | 1.00 | 7.7% | üî¥ |\\n| futures_term_structure | 5.4% | 1.00 | 5.4% | üî¥ |\\n| cboe_options_flow | 1.5% | 1.00 | 1.5% | üî¥ |\\n\\n### Top Features Driving Current Anomaly\\n| Feature | Importance | Current Value | Z-Score |\\n|---------|-----------|---------------|---------|\\n| spx_vs_ma200 | 0.091 | 10.72 | 1.00 |\\n| spx_lag1 | 0.088 | 6851.97 | 2.70 |\\n| spx_ret_5d | 0.082 | -1.73 | -0.89 |\\n| spx_lag5 | 0.082 | 6890.89 | 2.74 |\\n| spx_ret_13d | 0.075 | 2.15 | 0.43 |\\n| spx_ret_63d | 0.070 | 6.72 | 0.54 |\\n| rsi_14 | 0.067 | 59.06 | 0.14 |\\n| spx_momentum_z_10d | 0.067 | -0.48 | -0.34 |\\n| spx_momentum_z_21d | 0.062 | -1.57 | -1.16 |\\n| bb_width_20d | 0.058 | 5.64 | -0.13 |\\n\\n## 6. üîó Feature Correlation & Redundancy Analysis\\n\\n### High Correlation Pairs (>95%)\\n| Feature 1 | Feature 2 | Correlation |\\n|-----------|-----------|-------------|\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | SOFR_90D_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | CCC_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 7Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | BB_High_Yield_OAS_level | 1.000 |\\n| 1M_Treasury_zscore_252d | Yield_Curve_10Y3M_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3M_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | 3Y_Treasury_level | 1.000 |\\n| 1M_Treasury_zscore_252d | 20Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Corporate_Master_OAS_zscore_63d | 1.000 |\\n| 1M_Treasury_zscore_252d | 2Y_Treasury_zscore_252d | 1.000 |\\n| 1M_Treasury_zscore_252d | Breakeven_Inflation_10Y_zscore_63d | 1.000 |\\n\\n**Recommendation**: Consider removing 17552 redundant features to improve performance.\\n\\n## 7. ‚ö° Performance Profiling\\n\\n### Execution Time Breakdown\\n| Operation | Time (ms) | % of Total |\\n|-----------|-----------|------------|\\n| batch_10_detections | 168.6 | 89.7% |\\n| single_detection | 19.3 | 10.3% |\\n\\n## 8. üîç Common Failure Modes & Solutions\\n\\n‚úÖ No common failure modes detected.\\n\\n## 9. üí° What-If Scenario Analysis\\n\\n### VIX Spike to 40\\n**Scenario**: If VIX suddenly spikes to 40 (crisis level)\\n**Expected Behavior**: Ensemble score would likely exceed 93% (CRITICAL threshold)\\n**Current System Response**: Multiple detectors would fire: vix_regime_structure, vix_momentum, cross_asset_divergence\\n\\n### SKEW >150\\n**Scenario**: If SKEW index exceeds 150 (extreme tail risk)\\n**Expected Behavior**: tail_risk_complex detector triggers, ensemble score elevates\\n**Current System Response**: If SKEW features are available, system would classify as HIGH/CRITICAL\\n\\n### All CBOE Data Missing\\n**Scenario**: If CBOE features become unavailable\\n**Expected Behavior**: System continues to function with reduced capability\\n**Current System Response**: 5/15 detectors would be disabled, ensemble relies on VIX/SPX/futures detectors\\n\\n## 10. üìä Data Quality Heatmap\\n\\n### Feature Quality by Category\\n| Category | Total Features | Complete | Sparse | Missing | Quality Score |\\n|----------|---------------|----------|--------|---------|---------------|\\n| VIX | 78 | 73 | 0 | 5 | 93.6% |\\n| SPX | 47 | 44 | 0 | 3 | 93.6% |\\n| CBOE | 232 | 24 | 33 | 175 | 17.5% |\\n| Futures | 45 | 35 | 10 | 0 | 88.9% |\\n| Macro | 14 | 11 | 1 | 2 | 82.1% |\\n| Meta | 280 | 84 | 122 | 74 | 51.8% |\\n\\n## 11. üöÄ System Optimization Recommendations\\n\\n### üü¢ Optimization Opportunities\\n- Remove 17552 highly correlated features to reduce redundancy\\n- Investigate 197 stale features with high recent missing data\\n- Consider adding feature selection to reduce dimensionality\\n- Implement caching for expensive feature calculations\\n- Add monitoring alerts for data freshness\\n\\n## 12. üìñ Quick Reference: Troubleshooting Guide\\n\\n\\n### Common Issues & Quick Fixes\\n\\n**Issue**: System says \"data too old\"\\n- **Check**: `system.orchestrator.features.index[-1]`\\n- **Fix**: Run `system.refresh()` or retrain with fresh data\\n\\n**Issue**: Ensemble score always near 0% or 100%\\n- **Check**: Are thresholds computed? `system.orchestrator.anomaly_detector.statistical_thresholds`\\n- **Fix**: Retrain system to recalculate thresholds\\n\\n**Issue**: Many detectors show 0% coverage\\n- **Check**: CBOE files in `./CBOE_Data_Archive/`\\n- **Fix**: Download CBOE historical data or disable CBOE features in config\\n\\n**Issue**: \"Core data fetch failed\" error\\n- **Check**: Internet connection, yfinance API status\\n- **Fix**: Run `system.orchestrator.fetcher.fetch_core_data(...)` separately to debug\\n\\n**Issue**: High memory usage\\n- **Check**: Feature matrix size with `system.orchestrator.features.memory_usage(deep=True).sum()`\\n- **Fix**: Reduce training window in config.py (TRAINING_YEARS)\\n\\n**Issue**: Slow detection speed (>1 second)\\n- **Check**: Number of features and detectors active\\n- **Fix**: Reduce features, disable low-value detectors, or enable quick_mode\\n\\n**Issue**: NaN/Inf values in features\\n- **Check**: `system.orchestrator.features.isnull().sum()` and `np.isinf(system.orchestrator.features).sum()`\\n- **Fix**: Review feature_engine.py for division by zero or missing data handling\\n\\n\\n---\\n*Report generated in 2.34 seconds*'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enhanced_technical_introspector import TechnicalIntrospector\n",
    "\n",
    "introspector = TechnicalIntrospector(system)\n",
    "introspector.generate_report(quick_mode=False)\n",
    "\n",
    "# # Or specific diagnostics:\n",
    "# introspector.diagnose_current_state()\n",
    "# introspector.profile_performance()\n",
    "# introspector.check_data_freshness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89090432-5699-494a-9c40-5e94c01cd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEBUGGING BACKFILL ISSUES\n",
      "================================================================================\n",
      "\n",
      "Found 5 predictions to backfill\n",
      "\n",
      "Prediction details:\n",
      "                          prediction_id forecast_date  horizon  current_vix\n",
      "0  4182fda2-b6b2-4431-8c60-ace1d6c90543    2025-11-10        5        18.01\n",
      "1  30649c8c-0f0f-452d-81a3-a07e3282a1b4    2025-11-10        5        18.01\n",
      "2  ef51c1a5-1edb-4b8a-a781-52bfb35c4f41    2025-11-10        5        18.01\n",
      "3  529dc6d0-7197-4bd1-88eb-feea6d1cffaa    2024-01-07        5        13.20\n",
      "4  3eb0818d-10ae-45da-a316-a91dc2a67a77    2024-01-08        5        14.04\n",
      "\n",
      "================================================================================\n",
      "FETCHING VIX DATA\n",
      "================================================================================\n",
      "\n",
      "Downloaded VIX data:\n",
      "  Type: <class 'pandas.core.frame.DataFrame'>\n",
      "  Shape: (22, 5)\n",
      "  Columns: [('Close', '^VIX'), ('High', '^VIX'), ('Low', '^VIX'), ('Open', '^VIX'), ('Volume', '^VIX')]\n",
      "\n",
      "Extracted VIX series:\n",
      "  Type: <class 'pandas.core.series.Series'>\n",
      "  Length: 22\n",
      "  Index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "  Sample values:\n",
      "Date\n",
      "2025-11-04    19.00\n",
      "2025-11-05    18.01\n",
      "2025-11-06    19.50\n",
      "2025-11-07    19.08\n",
      "2025-11-10    17.77\n",
      "Name: ^VIX, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "TESTING VIX LOOKUPS\n",
      "================================================================================\n",
      "\n",
      "Prediction 1:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 2:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 3:\n",
      "  Forecast date: 2025-11-10\n",
      "  Target date: 2025-11-15\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'numpy.float64'>\n",
      "     Result value: 17.770000457763672\n",
      "     ‚úÖ Converted to float: 17.770000457763672\n",
      "\n",
      "Prediction 4:\n",
      "  Forecast date: 2024-01-07\n",
      "  Target date: 2024-01-12\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'float'>\n",
      "     Result value: nan\n",
      "     ‚úÖ Converted to float: nan\n",
      "\n",
      "Prediction 5:\n",
      "  Forecast date: 2024-01-08\n",
      "  Target date: 2024-01-13\n",
      "  Horizon: 5 days\n",
      "  ‚ö†Ô∏è  Exact match not found, trying asof...\n",
      "     Result type: <class 'float'>\n",
      "     Result value: nan\n",
      "     ‚úÖ Converted to float: nan\n",
      "\n",
      "================================================================================\n",
      "DIAGNOSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "If you see '‚ùå Multiple values' or conversion errors above,\n",
      "that's the source of the 'ambiguous Series' error.\n",
      "\n",
      "The fix needs to handle the exact data structure returned by yfinance.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Debug script to diagnose backfill issues\n",
    "Run this to see exactly what's happening with VIX data\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "# Database path\n",
    "db_path = Path(\"data_cache/predictions.db\")\n",
    "\n",
    "# Connect and get predictions needing backfill\n",
    "conn = sqlite3.connect(db_path)\n",
    "query = \"\"\"\n",
    "SELECT prediction_id, forecast_date, horizon, current_vix\n",
    "FROM forecasts\n",
    "WHERE actual_vix_change IS NULL\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "predictions = pd.read_sql_query(query, conn, parse_dates=['forecast_date'])\n",
    "conn.close()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DEBUGGING BACKFILL ISSUES\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFound {len(predictions)} predictions to backfill\")\n",
    "print(\"\\nPrediction details:\")\n",
    "print(predictions)\n",
    "\n",
    "# Fetch VIX data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FETCHING VIX DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "vix_df = yf.download(\"^VIX\", progress=False)\n",
    "print(f\"\\nDownloaded VIX data:\")\n",
    "print(f\"  Type: {type(vix_df)}\")\n",
    "print(f\"  Shape: {vix_df.shape if hasattr(vix_df, 'shape') else 'N/A'}\")\n",
    "print(f\"  Columns: {vix_df.columns.tolist() if hasattr(vix_df, 'columns') else 'N/A'}\")\n",
    "\n",
    "# Extract Close column\n",
    "if isinstance(vix_df, pd.DataFrame):\n",
    "    if 'Close' in vix_df.columns:\n",
    "        vix_series = vix_df['Close']\n",
    "    else:\n",
    "        vix_series = vix_df.iloc[:, 0]  # First column\n",
    "else:\n",
    "    vix_series = vix_df\n",
    "\n",
    "# Ensure Series\n",
    "if isinstance(vix_series, pd.DataFrame):\n",
    "    vix_series = vix_series.squeeze()\n",
    "\n",
    "print(f\"\\nExtracted VIX series:\")\n",
    "print(f\"  Type: {type(vix_series)}\")\n",
    "print(f\"  Length: {len(vix_series)}\")\n",
    "print(f\"  Index type: {type(vix_series.index)}\")\n",
    "print(f\"  Sample values:\")\n",
    "print(vix_series.tail())\n",
    "\n",
    "# Test lookup for each prediction\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TESTING VIX LOOKUPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, pred in predictions.iterrows():\n",
    "    forecast_date = pred['forecast_date']\n",
    "    horizon = pred['horizon']\n",
    "    target_date = forecast_date + pd.Timedelta(days=horizon)\n",
    "    \n",
    "    print(f\"\\nPrediction {idx + 1}:\")\n",
    "    print(f\"  Forecast date: {forecast_date.date()}\")\n",
    "    print(f\"  Target date: {target_date.date()}\")\n",
    "    print(f\"  Horizon: {horizon} days\")\n",
    "    \n",
    "    # Try exact lookup\n",
    "    if target_date in vix_series.index:\n",
    "        result = vix_series.loc[target_date]\n",
    "        print(f\"  ‚úÖ Exact match found\")\n",
    "        print(f\"     Result type: {type(result)}\")\n",
    "        print(f\"     Result value: {result}\")\n",
    "        \n",
    "        # Try to convert to float\n",
    "        try:\n",
    "            if isinstance(result, pd.Series):\n",
    "                if len(result) == 1:\n",
    "                    value = float(result.iloc[0])\n",
    "                    print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "                else:\n",
    "                    print(f\"     ‚ùå Multiple values: {len(result)}\")\n",
    "            else:\n",
    "                value = float(result)\n",
    "                print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Conversion failed: {e}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Exact match not found, trying asof...\")\n",
    "        result = vix_series.asof(target_date)\n",
    "        print(f\"     Result type: {type(result)}\")\n",
    "        print(f\"     Result value: {result}\")\n",
    "        \n",
    "        # Try to convert\n",
    "        try:\n",
    "            if isinstance(result, pd.Series):\n",
    "                if len(result) == 1:\n",
    "                    value = float(result.iloc[0])\n",
    "                    print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "                else:\n",
    "                    print(f\"     ‚ùå Multiple values: {len(result)}\")\n",
    "            else:\n",
    "                value = float(result)\n",
    "                print(f\"     ‚úÖ Converted to float: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Conversion failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DIAGNOSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nIf you see '‚ùå Multiple values' or conversion errors above,\")\n",
    "print(\"that's the source of the 'ambiguous Series' error.\")\n",
    "print(\"\\nThe fix needs to handle the exact data structure returned by yfinance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ffdb7ac-ebf4-469f-9afc-661da797cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   forecast_date  horizon  has_actual target_date\n",
      "0     2025-11-10        5           0  2025-11-15\n",
      "1     2025-11-09        5           0  2025-11-14\n",
      "2     2025-11-08        5           0  2025-11-13\n",
      "3     2025-11-05        5           1  2025-11-10\n",
      "4     2025-11-04        5           1  2025-11-09\n",
      "5     2025-11-03        5           1  2025-11-08\n",
      "6     2025-11-02        5           1  2025-11-07\n",
      "7     2025-11-01        5           1  2025-11-06\n",
      "8     2025-10-29        5           1  2025-11-03\n",
      "9     2025-10-28        5           1  2025-11-02\n",
      "10    2025-10-27        5           1  2025-11-01\n",
      "11    2025-10-26        5           1  2025-10-31\n",
      "12    2025-10-25        5           1  2025-10-30\n",
      "13    2025-10-22        5           1  2025-10-27\n",
      "14    2025-10-21        5           1  2025-10-26\n",
      "15    2025-10-20        5           1  2025-10-25\n",
      "16    2025-10-19        5           1  2025-10-24\n",
      "17    2025-10-18        5           1  2025-10-23\n",
      "18    2025-10-15        5           1  2025-10-20\n",
      "19    2025-10-14        5           1  2025-10-19\n",
      "20    2025-10-13        5           1  2025-10-18\n",
      "21    2025-10-12        5           1  2025-10-17\n",
      "22    2025-10-11        5           1  2025-10-16\n",
      "23    2025-10-08        5           1  2025-10-13\n",
      "24    2025-10-07        5           1  2025-10-12\n",
      "25    2025-10-06        5           1  2025-10-11\n",
      "26    2025-10-05        5           1  2025-10-10\n",
      "27    2025-10-04        5           0  2025-10-09\n",
      "28    2025-10-01        5           0  2025-10-06\n",
      "29    2025-09-30        5           0  2025-10-05\n",
      "30    2025-09-29        5           0  2025-10-04\n",
      "31    2025-09-28        5           0  2025-10-03\n",
      "32    2025-09-27        5           0  2025-10-02\n",
      "33    2025-09-24        5           0  2025-09-29\n",
      "34    2025-09-23        5           0  2025-09-28\n",
      "35    2025-09-22        5           0  2025-09-27\n",
      "36    2025-09-21        5           0  2025-09-26\n",
      "37    2025-09-20        5           0  2025-09-25\n",
      "38    2025-09-17        5           0  2025-09-22\n",
      "39    2025-09-16        5           0  2025-09-21\n",
      "40    2025-09-15        5           0  2025-09-20\n",
      "41    2025-09-14        5           0  2025-09-19\n",
      "42    2025-09-13        5           0  2025-09-18\n",
      "43    2025-09-10        5           0  2025-09-15\n",
      "44    2025-09-09        5           0  2025-09-14\n",
      "45    2025-09-08        5           0  2025-09-13\n",
      "46    2025-09-07        5           0  2025-09-12\n",
      "47    2025-09-03        5           0  2025-09-08\n",
      "48    2025-09-02        5           0  2025-09-07\n",
      "49    2025-09-01        5           0  2025-09-06\n",
      "\n",
      "Today: 2025-11-10\n",
      "Predictions with actuals: 24/50\n"
     ]
    }
   ],
   "source": [
    "# Quick diagnostic script\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data_cache/predictions.db')\n",
    "\n",
    "# Check prediction dates\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        forecast_date,\n",
    "        horizon,\n",
    "        actual_vix_change IS NOT NULL as has_actual,\n",
    "        date(forecast_date, '+' || horizon || ' days') as target_date\n",
    "    FROM forecasts\n",
    "    ORDER BY forecast_date DESC\n",
    "    LIMIT 50\n",
    "\"\"\", conn, parse_dates=['forecast_date', 'target_date'])\n",
    "\n",
    "print(df)\n",
    "print(f\"\\nToday: {pd.Timestamp.now().date()}\")\n",
    "print(f\"Predictions with actuals: {df['has_actual'].sum()}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd39e3d5-d486-4cbf-b415-84c81ed6e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DUPLICATE CLEANUP\n",
      "================================================================================\n",
      "‚úÖ No duplicates found\n",
      "\n",
      "================================================================================\n",
      "DATABASE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total predictions: 75\n",
      "  ‚úÖ With actuals: 15\n",
      "  ‚è≥ Pending actuals: 60\n",
      "\n",
      "Date range: 2024-01-07T00:00:00 to 2025-11-10T00:00:00\n",
      "Remaining duplicates: 0\n",
      "  ‚úÖ No duplicates\n",
      "\n",
      "Predictions by cohort:\n",
      "  mid_cycle                :   45\n",
      "  monthly_opex_minus_1     :   11\n",
      "  fomc_minus_3             :    7\n",
      "  earnings_heavy           :    6\n",
      "  monthly_opex_minus_5     :    6\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Standalone script to clean duplicate predictions and show database stats.\n",
    "Run from src/ directory: python cleanup_duplicates.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we can import from current directory\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = \"data_cache/predictions.db\"\n",
    "\n",
    "def remove_duplicates():\n",
    "    \"\"\"Remove duplicate predictions, keeping the earliest by timestamp.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DUPLICATE CLEANUP\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Find duplicates\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT forecast_date, horizon, COUNT(*) as count\n",
    "        FROM forecasts\n",
    "        GROUP BY forecast_date, horizon\n",
    "        HAVING count > 1\n",
    "    \"\"\")\n",
    "    \n",
    "    duplicates = cursor.fetchall()\n",
    "    \n",
    "    if len(duplicates) == 0:\n",
    "        print(\"‚úÖ No duplicates found\")\n",
    "        conn.close()\n",
    "        return 0\n",
    "    \n",
    "    print(f\"‚ö†Ô∏è  Found {len(duplicates)} duplicate date-horizon pairs\\n\")\n",
    "    \n",
    "    # Show sample duplicates\n",
    "    print(\"Sample duplicates:\")\n",
    "    for i, (forecast_date, horizon, count) in enumerate(duplicates[:5], 1):\n",
    "        print(f\"  {i}. {forecast_date} (horizon={horizon}): {count} copies\")\n",
    "    \n",
    "    if len(duplicates) > 5:\n",
    "        print(f\"  ... and {len(duplicates) - 5} more\")\n",
    "    \n",
    "    # Remove duplicates (keep earliest)\n",
    "    total_removed = 0\n",
    "    for forecast_date, horizon, count in duplicates:\n",
    "        cursor = conn.execute(\"\"\"\n",
    "            DELETE FROM forecasts\n",
    "            WHERE forecast_date = ? AND horizon = ?\n",
    "            AND prediction_id NOT IN (\n",
    "                SELECT prediction_id FROM forecasts\n",
    "                WHERE forecast_date = ? AND horizon = ?\n",
    "                ORDER BY timestamp ASC\n",
    "                LIMIT 1\n",
    "            )\n",
    "        \"\"\", (forecast_date, horizon, forecast_date, horizon))\n",
    "        \n",
    "        removed = cursor.rowcount\n",
    "        total_removed += removed\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Removed {total_removed} duplicate predictions\")\n",
    "    return total_removed\n",
    "\n",
    "\n",
    "def show_stats():\n",
    "    \"\"\"Show database statistics.\"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATABASE STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Total predictions\n",
    "    cursor = conn.execute(\"SELECT COUNT(*) FROM forecasts\")\n",
    "    total = cursor.fetchone()[0]\n",
    "    \n",
    "    # With actuals\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM forecasts\n",
    "        WHERE actual_vix_change IS NOT NULL\n",
    "    \"\"\")\n",
    "    with_actuals = cursor.fetchone()[0]\n",
    "    \n",
    "    # Date range\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT MIN(forecast_date) as earliest, MAX(forecast_date) as latest\n",
    "        FROM forecasts\n",
    "    \"\"\")\n",
    "    earliest, latest = cursor.fetchone()\n",
    "    \n",
    "    # Remaining duplicates (should be 0 after cleanup)\n",
    "    cursor = conn.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM (\n",
    "            SELECT forecast_date, horizon, COUNT(*) as count\n",
    "            FROM forecasts\n",
    "            GROUP BY forecast_date, horizon\n",
    "            HAVING count > 1\n",
    "        )\n",
    "    \"\"\")\n",
    "    remaining_dupes = cursor.fetchone()[0]\n",
    "    \n",
    "    print(f\"\\nTotal predictions: {total}\")\n",
    "    print(f\"  ‚úÖ With actuals: {with_actuals}\")\n",
    "    print(f\"  ‚è≥ Pending actuals: {total - with_actuals}\")\n",
    "    print(f\"\\nDate range: {earliest} to {latest}\")\n",
    "    print(f\"Remaining duplicates: {remaining_dupes}\")\n",
    "    \n",
    "    if remaining_dupes > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  WARNING: {remaining_dupes} duplicate pairs still exist!\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ No duplicates\")\n",
    "    \n",
    "    # Cohort breakdown\n",
    "    print(f\"\\nPredictions by cohort:\")\n",
    "    df = pd.read_sql_query(\"\"\"\n",
    "        SELECT calendar_cohort, COUNT(*) as count\n",
    "        FROM forecasts\n",
    "        GROUP BY calendar_cohort\n",
    "        ORDER BY count DESC\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"  {row['calendar_cohort']:25s}: {row['count']:4d}\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run cleanup and show stats.\"\"\"\n",
    "    if not Path(DB_PATH).exists():\n",
    "        print(f\"‚ùå Database not found: {DB_PATH}\")\n",
    "        print(f\"   Run batch forecasting first:\")\n",
    "        print(f\"   python integrated_system_production.py --mode batch \\\\\")\n",
    "        print(f\"     --start-date 2025-08-01 --end-date 2025-11-10\")\n",
    "        return\n",
    "    \n",
    "    # Remove duplicates\n",
    "    removed = remove_duplicates()\n",
    "    \n",
    "    # Show final stats\n",
    "    show_stats()\n",
    "    \n",
    "    if removed > 0:\n",
    "        print(\"‚úÖ Database cleaned successfully\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0962497-4446-48c7-a4cf-13285900e057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE SCHEMA:\n",
      "CREATE TABLE forecasts (\n",
      "            prediction_id TEXT PRIMARY KEY, timestamp DATETIME, forecast_date DATE, horizon INTEGER, calendar_cohort TEXT, cohort_weight REAL, point_estimate REAL, q10 REAL, q25 REAL, q50 REAL, q75 REAL, q90 REAL, prob_low REAL, prob_normal REAL, prob_elevated REAL, prob_crisis REAL, confidence_score REAL, feature_quality REAL, regime_stability REAL, num_features_used INTEGER, missing_features TEXT, current_vix REAL, actual_vix_change REAL, actual_regime TEXT, point_error REAL, quantile_coverage TEXT, features_used TEXT, model_version TEXT, created_at DATETIME\n",
      "        )\n",
      "\n",
      "================================================================================\n",
      "\n",
      "RECENT PREDICTIONS:\n",
      "('2025-11-10T00:00:00', 5, 0.012065990827977657, None, None, '2025-11-10T12:26:03.862453')\n",
      "('2025-11-09T00:00:00', 5, -5.265535831451416, None, None, '2025-11-10T13:52:39.469317')\n",
      "('2025-11-08T00:00:00', 5, -0.30410364270210266, None, None, '2025-11-10T13:52:33.712613')\n",
      "('2025-11-05T00:00:00', 5, -1.2874683141708374, 0.9174302896359119, 'Normal', '2025-11-10T21:27:03.037189')\n",
      "('2025-11-04T00:00:00', 5, 6.006715297698975, 12.832643973240721, 'Normal', '2025-11-10T21:26:56.892967')\n",
      "('2025-11-03T00:00:00', 5, 4.480521202087402, 12.765956487425873, 'Normal', '2025-11-10T21:26:50.502377')\n",
      "('2025-11-02T00:00:00', 5, 14.196897506713867, 16.199755390089386, 'Normal', '2025-11-10T21:26:43.164803')\n",
      "('2025-11-01T00:00:00', 5, 6.797454833984375, 23.495883768903997, 'Normal', '2025-11-10T21:26:35.293618')\n",
      "('2025-10-29T00:00:00', 5, 4.506311893463135, 4.886983482268475, 'Normal', '2025-11-10T21:26:27.423912')\n",
      "('2025-10-28T00:00:00', 5, -5.159221172332764, 0.8092560876948225, 'Normal', '2025-11-10T21:26:21.260576')\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SUMMARY STATS:\n",
      "Total forecasts: 75\n",
      "With actuals: 24\n",
      "Earliest forecast: 2024-01-07T00:00:00\n",
      "Latest forecast: 2025-11-10T00:00:00\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "db_path = \"data_cache/predictions.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Show table structure\n",
    "cursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table' AND name='forecasts'\")\n",
    "print(\"TABLE SCHEMA:\")\n",
    "print(cursor.fetchone()[0])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Show sample records with and without actuals\n",
    "cursor.execute(\"\"\"\n",
    "SELECT \n",
    "    forecast_date,\n",
    "    horizon,\n",
    "    point_estimate,\n",
    "    actual_vix_change,\n",
    "    actual_regime,\n",
    "    created_at\n",
    "FROM forecasts \n",
    "ORDER BY forecast_date DESC \n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"RECENT PREDICTIONS:\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Additional stats\n",
    "cursor.execute(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total,\n",
    "    SUM(CASE WHEN actual_vix_change IS NOT NULL THEN 1 ELSE 0 END) as with_actuals,\n",
    "    MIN(forecast_date) as earliest,\n",
    "    MAX(forecast_date) as latest\n",
    "FROM forecasts\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"SUMMARY STATS:\")\n",
    "stats = cursor.fetchone()\n",
    "print(f\"Total forecasts: {stats[0]}\")\n",
    "print(f\"With actuals: {stats[1]}\")\n",
    "print(f\"Earliest forecast: {stats[2]}\")\n",
    "print(f\"Latest forecast: {stats[3]}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55ecaa34-6a95-4396-952f-2bca720a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUG-OCT FORECASTS AND THEIR ACTUALS:\n",
      "Forecast     Target       Current VIX  Actual Change   Regime\n",
      "======================================================================\n",
      "2025-08-06   2025-08-11   20.38        MISSING         -\n",
      "2025-08-09   2025-08-14   17.52        MISSING         -\n",
      "2025-08-10   2025-08-15   17.85        MISSING         -\n",
      "2025-08-11   2025-08-16   16.77        MISSING         -\n",
      "2025-08-12   2025-08-17   16.57        MISSING         -\n",
      "2025-08-13   2025-08-18   15.15        MISSING         -\n",
      "2025-08-16   2025-08-21   16.25        MISSING         -\n",
      "2025-08-17   2025-08-22   14.73        MISSING         -\n",
      "2025-08-18   2025-08-23   14.49        MISSING         -\n",
      "2025-08-19   2025-08-24   14.83        MISSING         -\n",
      "2025-08-20   2025-08-25   15.09        MISSING         -\n",
      "2025-08-23   2025-08-28   14.99        MISSING         -\n",
      "2025-08-24   2025-08-29   15.57        MISSING         -\n",
      "2025-08-25   2025-08-30   15.69        MISSING         -\n",
      "2025-08-26   2025-08-31   16.60        MISSING         -\n",
      "2025-08-27   2025-09-01   14.22        MISSING         -\n",
      "2025-08-30   2025-09-04   14.79        MISSING         -\n",
      "2025-08-31   2025-09-05   14.62        MISSING         -\n",
      "2025-09-01   2025-09-06   14.85        MISSING         -\n",
      "2025-09-02   2025-09-07   14.43        MISSING         -\n",
      "2025-09-03   2025-09-08   15.36        MISSING         -\n",
      "2025-09-07   2025-09-12   17.17        MISSING         -\n",
      "2025-09-08   2025-09-13   16.35        MISSING         -\n",
      "2025-09-09   2025-09-14   15.30        MISSING         -\n",
      "2025-09-10   2025-09-15   15.18        MISSING         -\n",
      "2025-09-13   2025-09-18   15.11        MISSING         -\n",
      "2025-09-14   2025-09-19   15.04        MISSING         -\n",
      "2025-09-15   2025-09-20   15.35        MISSING         -\n",
      "2025-09-16   2025-09-21   14.71        MISSING         -\n",
      "2025-09-17   2025-09-22   14.76        MISSING         -\n",
      "2025-09-20   2025-09-25   15.69        MISSING         -\n",
      "2025-09-21   2025-09-26   16.36        MISSING         -\n",
      "2025-09-22   2025-09-27   15.72        MISSING         -\n",
      "2025-09-23   2025-09-28   15.70        MISSING         -\n",
      "2025-09-24   2025-09-29   15.45        MISSING         -\n",
      "2025-09-27   2025-10-02   16.10        MISSING         -\n",
      "2025-09-28   2025-10-03   16.64        MISSING         -\n",
      "2025-09-29   2025-10-04   16.18        MISSING         -\n",
      "2025-09-30   2025-10-05   16.74        MISSING         -\n",
      "2025-10-01   2025-10-06   15.29        MISSING         -\n",
      "2025-10-04   2025-10-09   16.12        MISSING         -\n",
      "======================================================================\n",
      "With actuals: 0\n",
      "Missing actuals: 41\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"data_cache/predictions.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "SELECT \n",
    "    forecast_date,\n",
    "    horizon,\n",
    "    date(forecast_date, '+' || horizon || ' days') as target_date,\n",
    "    current_vix,\n",
    "    actual_vix_change,\n",
    "    actual_regime\n",
    "FROM forecasts\n",
    "WHERE forecast_date BETWEEN '2025-08-01' AND '2025-10-05'\n",
    "ORDER BY forecast_date\n",
    "\"\"\")\n",
    "\n",
    "print(\"AUG-OCT FORECASTS AND THEIR ACTUALS:\")\n",
    "print(f\"{'Forecast':<12} {'Target':<12} {'Current VIX':<12} {'Actual Change':<15} {'Regime'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "has_actuals = 0\n",
    "missing_actuals = 0\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    forecast, horizon, target, curr_vix, actual_change, regime = row\n",
    "    if actual_change is not None:\n",
    "        has_actuals += 1\n",
    "        print(f\"{forecast[:10]:<12} {target:<12} {curr_vix:<12.2f} {actual_change:<15.2f} {regime}\")\n",
    "    else:\n",
    "        missing_actuals += 1\n",
    "        print(f\"{forecast[:10]:<12} {target:<12} {curr_vix:<12.2f} {'MISSING':<15} -\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"With actuals: {has_actuals}\")\n",
    "print(f\"Missing actuals: {missing_actuals}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95a1658-adf0-46c0-868f-4bde604c2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING VIX DATA AVAILABILITY FOR TARGET DATES:\n",
      "==================================================\n",
      "‚úÖ 2025-08-11\n",
      "‚úÖ 2025-08-14\n",
      "‚úÖ 2025-08-15\n",
      "‚ùå 2025-08-16\n",
      "‚ùå 2025-08-17\n",
      "‚úÖ 2025-08-18\n",
      "‚úÖ 2025-08-21\n",
      "‚úÖ 2025-08-22\n",
      "‚ùå 2025-08-23\n",
      "‚ùå 2025-08-24\n",
      "‚úÖ 2025-08-25\n",
      "‚úÖ 2025-08-28\n",
      "‚úÖ 2025-08-29\n",
      "‚ùå 2025-08-30\n",
      "‚ùå 2025-08-31\n",
      "‚ùå 2025-09-01\n",
      "‚úÖ 2025-09-04\n",
      "‚úÖ 2025-09-05\n",
      "‚ùå 2025-09-06\n",
      "‚ùå 2025-09-07\n",
      "‚úÖ 2025-09-08\n",
      "‚úÖ 2025-09-12\n",
      "‚ùå 2025-09-13\n",
      "‚ùå 2025-09-14\n",
      "‚úÖ 2025-09-15\n",
      "‚úÖ 2025-09-18\n",
      "‚úÖ 2025-09-19\n",
      "‚ùå 2025-09-20\n",
      "‚ùå 2025-09-21\n",
      "‚úÖ 2025-09-22\n",
      "‚úÖ 2025-09-25\n",
      "‚úÖ 2025-09-26\n",
      "‚ùå 2025-09-27\n",
      "‚ùå 2025-09-28\n",
      "‚úÖ 2025-09-29\n",
      "‚úÖ 2025-10-02\n",
      "‚úÖ 2025-10-03\n",
      "‚ùå 2025-10-04\n",
      "‚ùå 2025-10-05\n",
      "‚úÖ 2025-10-06\n",
      "‚úÖ 2025-10-09\n",
      "==================================================\n",
      "Available: 24\n",
      "Missing: 17\n",
      "\n",
      "VIX data range: 2009-08-20 00:00:00 to 2025-11-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vix = pd.read_parquet(\"data_cache/yahoo__VIX.parquet\")\n",
    "\n",
    "# Convert index to date strings\n",
    "vix_dates = set(vix.index.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# Target dates from your forecasts\n",
    "target_dates = [\n",
    "    \"2025-08-11\", \"2025-08-14\", \"2025-08-15\", \"2025-08-16\", \"2025-08-17\",\n",
    "    \"2025-08-18\", \"2025-08-21\", \"2025-08-22\", \"2025-08-23\", \"2025-08-24\",\n",
    "    \"2025-08-25\", \"2025-08-28\", \"2025-08-29\", \"2025-08-30\", \"2025-08-31\",\n",
    "    \"2025-09-01\", \"2025-09-04\", \"2025-09-05\", \"2025-09-06\", \"2025-09-07\",\n",
    "    \"2025-09-08\", \"2025-09-12\", \"2025-09-13\", \"2025-09-14\", \"2025-09-15\",\n",
    "    \"2025-09-18\", \"2025-09-19\", \"2025-09-20\", \"2025-09-21\", \"2025-09-22\",\n",
    "    \"2025-09-25\", \"2025-09-26\", \"2025-09-27\", \"2025-09-28\", \"2025-09-29\",\n",
    "    \"2025-10-02\", \"2025-10-03\", \"2025-10-04\", \"2025-10-05\", \"2025-10-06\",\n",
    "    \"2025-10-09\"\n",
    "]\n",
    "\n",
    "print(\"CHECKING VIX DATA AVAILABILITY FOR TARGET DATES:\")\n",
    "print(\"=\"*50)\n",
    "available = 0\n",
    "missing = 0\n",
    "\n",
    "for date in target_dates:\n",
    "    if date in vix_dates:\n",
    "        available += 1\n",
    "        print(f\"‚úÖ {date}\")\n",
    "    else:\n",
    "        missing += 1\n",
    "        print(f\"‚ùå {date}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"Available: {available}\")\n",
    "print(f\"Missing: {missing}\")\n",
    "\n",
    "# Show VIX data range around these dates\n",
    "print(f\"\\nVIX data range: {vix.index.min()} to {vix.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacaae6-d4eb-47b3-a64f-0ada390921f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
